<div style="background: linear-gradient(135deg, #2563eb, #1e40af); padding: 24px; border-radius: 8px; color: white; text-align: center; margin-bottom: 24px;">
  <h2 style="margin: 0; color: white;">ğŸ‘ï¸ Qwen2.5-VL Vision-Language Model</h2>
  <p style="margin: 8px 0 0 0; opacity: 0.9;">More Useful Vision-Language Model - AI Expert for Understanding Images, Videos, and Documents</p>
</div>

## ğŸ¯ Product Overview

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

Qwen2.5-VL is a more useful vision-language model built by Alibaba Cloud's Qwen team based on Qwen2-VL and incorporating valuable feedback from numerous developers. This model has achieved significant improvements in visual understanding, agent capabilities, video analysis, visual localization, and structured output.

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ğŸš€ Core Upgrades</strong><br>
  Continuously optimized based on developer feedback, Qwen2.5-VL has achieved major breakthroughs in practicality and functional completeness, becoming a more practical vision-language AI assistant.
</div>

</div>

## âœ¨ Core Features

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
  <strong>ğŸ‘ï¸ Visual Understanding of Objects</strong><br>
  Not only can skillfully recognize common objects such as flowers, birds, fish, and insects, but can also analyze text, charts, icons, graphics, and layouts in images.
</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
  <strong>ğŸ¤– Intelligent Agency</strong><br>
  Directly acts as a visual agent with reasoning and dynamic tool command functions, applicable for computer and mobile device operation control.
</div>

<div style="background: #fef7ff; border-left: 4px solid #a855f7; padding: 16px; border-radius: 4px;">
  <strong>ğŸ¬ Long Video Understanding</strong><br>
  Can understand videos longer than 1 hour, with new functionality to capture events through precise localization of relevant video segments.
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
  <strong>ğŸ¯ Visual Localization Capability</strong><br>
  Can accurately locate objects in images by generating bounding boxes or points, and can provide stable JSON output for coordinates and attributes.
</div>

<div style="background: #ecfdf5; border-left: 4px solid #10b981; padding: 16px; border-radius: 4px;">
  <strong>ğŸ“Š Structured Output</strong><br>
  For scanned data such as invoices, tables, and forms, supports structured output of their content, beneficial for applications in finance, business, and other fields.
</div>

</div>

## ğŸ” Visual Understanding Capabilities

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<h3 style="margin-top: 0; color: #1e40af;">ğŸŒŸ Comprehensive Visual Recognition</h3>

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: white; border: 2px solid #dcfce7; border-radius: 8px; padding: 16px;">
  <h4 style="margin-top: 0; color: #059669; text-align: center;">ğŸŒº Natural Object Recognition</h4>
  <div style="background: #f0fdf4; padding: 12px; border-radius: 6px; margin: 8px 0;">
    <strong>Recognition Scope:</strong><br>
    â€¢ Flower and plant classification<br>
    â€¢ Bird and animal identification<br>
    â€¢ Fish and aquatic life<br>
    â€¢ Insect and microorganism detection
  </div>
  <div style="text-align: center; margin-top: 12px;">
    <span style="background: #dcfce7; color: #059669; padding: 4px 12px; border-radius: 12px; font-size: 12px;">Professional-grade Accuracy</span>
  </div>
</div>

<div style="background: white; border: 2px solid #dbeafe; border-radius: 8px; padding: 16px;">
  <h4 style="margin-top: 0; color: #2563eb; text-align: center;">ğŸ“ Text and Chart Analysis</h4>
  <div style="background: #eff6ff; padding: 12px; border-radius: 6px; margin: 8px 0;">
    <strong>Analysis Capabilities:</strong><br>
    â€¢ Image text extraction<br>
    â€¢ Chart data interpretation<br>
    â€¢ Icon and symbol recognition<br>
    â€¢ Layout structure analysis
  </div>
  <div style="text-align: center; margin-top: 12px;">
    <span style="background: #dbeafe; color: #2563eb; padding: 4px 12px; border-radius: 12px; font-size: 12px;">Multimodal Understanding</span>
  </div>
</div>

<div style="background: white; border: 2px solid #f3e8ff; border-radius: 8px; padding: 16px;">
  <h4 style="margin-top: 0; color: #a855f7; text-align: center;">ğŸ¨ Graphic Design Understanding</h4>
  <div style="background: #fef7ff; padding: 12px; border-radius: 6px; margin: 8px 0;">
    <strong>Design Analysis:</strong><br>
    â€¢ Graphic element recognition<br>
    â€¢ Design style analysis<br>
    â€¢ Color scheme understanding<br>
    â€¢ Visual hierarchy deconstruction
  </div>
  <div style="text-align: center; margin-top: 12px;">
    <span style="background: #f3e8ff; color: #a855f7; padding: 4px 12px; border-radius: 12px; font-size: 12px;">Aesthetic Perception</span>
  </div>
</div>

</div>

</div>

## ğŸ¬ Long Video Understanding

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<h3 style="margin-top: 0; color: #1e40af;">â° Extended Duration Video Analysis</h3>

<div style="overflow-x: auto; margin: 16px 0;">
<table style="width: 100%; border-collapse: collapse; background: white; border-radius: 6px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
  <thead style="background: #f8fafc;">
    <tr>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Video Length</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Analysis Capabilities</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Application Scenarios</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">
        <span style="background: #dcfce7; color: #059669; padding: 4px 8px; border-radius: 4px; font-size: 12px; font-weight: 500;">Short Videos (< 10 minutes)</span>
      </td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Fine-grained action recognition, emotion analysis</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Social media content analysis</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">
        <span style="background: #dbeafe; color: #2563eb; padding: 4px 8px; border-radius: 4px; font-size: 12px; font-weight: 500;">Medium Videos (10-30 minutes)</span>
      </td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Event sequence understanding, topic extraction</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Educational training video analysis</td>
    </tr>
    <tr>
      <td style="padding: 12px;">
        <span style="background: #fed7aa; color: #ea580c; padding: 4px 8px; border-radius: 4px; font-size: 12px; font-weight: 500;">Long Videos (> 1 hour)</span>
      </td>
      <td style="padding: 12px;">Global understanding, event localization, segment retrieval</td>
      <td style="padding: 12px;">Movie analysis, meeting records</td>
    </tr>
  </tbody>
</table>
</div>

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
  <strong>ğŸ¯ Event Capture</strong><br>
  <div style="margin-top: 8px; color: #065f46;">
    â€¢ Automatic key event recognition<br>
    â€¢ Precise timestamp localization<br>
    â€¢ Intelligent related segment retrieval<br>
    â€¢ Event correlation analysis
  </div>
</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
  <strong>ğŸ“Š Content Understanding</strong><br>
  <div style="margin-top: 8px; color: #1e3a8a;">
    â€¢ Video topic extraction<br>
    â€¢ Plot development tracking<br>
    â€¢ Character behavior analysis<br>
    â€¢ Scene change detection
  </div>
</div>

</div>

</div>

## ğŸš€ Application Scenarios

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
  <strong>ğŸ’¼ Business Office</strong><br>
  <div style="margin-top: 8px; color: #1e3a8a;">
    â€¢ Document automation processing<br>
    â€¢ Invoice and receipt recognition<br>
    â€¢ Table data extraction<br>
    â€¢ Office workflow automation
  </div>
</div>

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
  <strong>ğŸ“ Education and Training</strong><br>
  <div style="margin-top: 8px; color: #065f46;">
    â€¢ Educational video analysis<br>
    â€¢ Learning content extraction<br>
    â€¢ Knowledge point localization<br>
    â€¢ Interactive teaching assistance
  </div>
</div>

<div style="background: #fef7ff; border-left: 4px solid #a855f7; padding: 16px; border-radius: 4px;">
  <strong>ğŸ¬ Media Entertainment</strong><br>
  <div style="margin-top: 8px; color: #6b21a8;">
    â€¢ Video content analysis<br>
    â€¢ Highlight segment extraction<br>
    â€¢ Subtitle generation optimization<br>
    â€¢ Content recommendation systems
  </div>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
  <strong>ğŸ¥ Healthcare</strong><br>
  <div style="margin-top: 8px; color: #92400e;">
    â€¢ Medical image analysis<br>
    â€¢ Medical record document processing<br>
    â€¢ Examination report interpretation<br>
    â€¢ Diagnostic assistance support
  </div>
</div>

</div>

## ğŸ“– User Guide

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ğŸ’¡ After Deployment</strong><br>
  After completing the model deployment, you can view the model usage instructions on the Computing Nest service instance overview page, which provides API call examples, internal network access addresses, public network access addresses (available after enabling public network access), and Api_Key.
</div>

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">
  <div style="text-align: center; margin-bottom: 16px;">
    <img src="../image-en/img-llm-use-desc.png" alt="Model usage instructions interface" style="max-width: 100%; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
  </div>
</div>

### ğŸ”Œ API Call Methods

#### ğŸ–¥ï¸ Curl Command Call

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<div style="text-align: center; margin-bottom: 16px;">
  <img src="../image-en/img-api-call.png" alt="API call example" style="max-width: 100%; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ğŸ“‹ Parameter Description</strong><br>
  â€¢ <code>${ServerIP}</code>: IP address from internal or public network address<br>
  â€¢ <code>${ApiKey}</code>: ApiKey provided on the page<br>
  â€¢ <code>${ModelName}</code>: Model name
</div>

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ğŸ–¼ï¸ Image Format Support</strong><br>
  The <code>image_url</code> parameter supports two formats:<br>
  â€¢ <strong>HTTP URL</strong>: e.g., <code>https://modelscope.oss-cn-beijing.aliyuncs.com/resource/qwen.png</code><br>
  â€¢ <strong>Base64 Encoding</strong>: <code>data:image/jpeg;base64,&lt;base64 encoded image format&gt;</code>
</div>

Curl command calls can directly use the API call examples from the service instance overview page. The specific structure for calling the model API is as follows:

```bash
curl -X Post http://${ServerIP}:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -H "Authorization: ${ApiKey}" \
    -d '{
        "model": "${ModelName}",
        "messages": [
        {
            "role": "system",
            "content": "You are a helpful assistant."
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "data:image/jpeg;base64,<base64 encoded image format>"
                    }
                },
                {
                    "type": "text",
                    "text": "How many sheep are there in the picture?"
                }
            ]
        }
        ]
    }'
```

</div>

#### ğŸ Python SDK Call

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>âš™ï¸ Configuration Instructions</strong><br>
  â€¢ <code>${ApiKey}</code>: Fill in the ApiKey from the page<br>
  â€¢ <code>${ServerUrl}</code>: Fill in the public or internal network address from the page, must include <code>/v1</code>
</div>

The following is Python example code that supports image and video processing:

```python
import base64
import requests
from openai import OpenAI

##### API Configuration #####
openai_api_key = "${ApiKey}"
openai_api_base = "${ServerUrl}"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

models = client.models.list()
model = models.data[0].id


def encode_base64_content_from_url(content_url: str) -> str:
    """Encode a content retrieved from a remote url to base64 format."""
    
    with requests.get(content_url) as response:
        response.raise_for_status()
        result = base64.b64encode(response.content).decode("utf-8")
    
    return result


def infer_image():
    image_url = "https://qianwen-res.oss-cn-beijing.aliyuncs.com/QVQ/demo.png"
    
    stream = True
    
    image_base64 = encode_base64_content_from_url(image_url)
    
    chat_completion_from_base64 = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "Answer in Chinese, what number should be in the box in the image?",
                    },
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"},
                    },
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=stream,
    )
    
    if stream:
        for chunk in chat_completion_from_base64:
            print(chunk.choices[0].delta.content, end="")
    else:
        result = chat_completion_from_base64.choices[0].message.content
        print(result)


def infer_video():
    video_url = "https://pai-quickstart-predeploy-hangzhou.oss-cn-hangzhou.aliyuncs.com/modelscope/algorithms/ms-swift/video_demo.mp4"
    
    stream = True
    
    video_base64 = encode_base64_content_from_url(video_url)
    
    chat_completion_from_base64 = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "Please describe the video content"},
                    {
                        "type": "video_url",
                        "video_url": {"url": f"data:video/mp4;base64,{video_base64}"},
                    },
                ],
            }
        ],
        model=model,
        max_completion_tokens=512,
        stream=stream,
    )
    
    if stream:
        for chunk in chat_completion_from_base64:
            print(chunk.choices[0].delta.content, end="")
    else:
        result = chat_completion_from_base64.choices[0].message.content
        print(result)


if __name__ == "__main__":
    infer_image()
    infer_video()
```

</div>

---

<div style="text-align: center; padding: 16px; background: #f8fafc; border-radius: 6px; margin-top: 24px;">
  <p style="margin: 0; color: #64748b; font-size: 14px;">
    ğŸ‘ï¸ <strong>Qwen2.5-VL</strong> | More Useful Vision-Language Model, AI's Eye for Understanding the World
  </p>
</div>