# 简介
我们发布了 gpt-oss-120b 和 gpt-oss-20b——两款性能卓越的开放轻量级语言模型，可在低成本下实现强大的实际应用性能。这些模型在灵活的 Apache 2.0 许可证下提供，与同等规模的开放模型相比，在推理任务中表现更优，展现出强大的工具使用能力，并针对在消费级硬件上高效部署进行了优化。它们通过强化学习与 OpenAI 最先进内部模型（包括 o3 及其他前沿系统）所启发的技术相结合进行训练。

Gpt-oss-120b 模型在核心推理基准测试中与 OpenAI o4-mini 模型几乎持平，同时能在单个 80GB GPU 上高效运行。Gpt-oss-20b 模型在常见基准测试中与 OpenAI o3‑mini 模型取得类似结果，且可在仅配备 16GB 内存的边缘设备上运行，使其成为设备端应用、本地推理或无需昂贵基础设施的快速迭代的理想选择。这两个模型在工具使用、少样本函数调用、CoT推理（如在 Tau-Bench 智能体评估套件中的结果所示）以及 HealthBench 测试中表现强劲（甚至超越了 OpenAI o1 和 GPT‑4o 等专有模型）。

