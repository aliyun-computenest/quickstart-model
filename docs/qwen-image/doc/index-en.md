<div style="background: linear-gradient(135deg, #2563eb, #1e40af); padding: 24px; border-radius: 8px; color: white; text-align: center; margin-bottom: 24px;">
  <h2 style="margin: 0; color: white;">ğŸ¨ Qwen-Image</h2>
  <p style="margin: 8px 0 0 0; opacity: 0.9;">Qwen Series Image Generation Foundation Model - Specialized in Complex Text Rendering & Precise Image Editing</p>
  <div style="margin-top: 20px;">
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">ğŸ¯ Text Rendering</span>
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">âœ¨ Image Editing</span>
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">ğŸ§  Intelligent Understanding</span>
  </div>
</div>

## ğŸŒŸ Model Overview

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

We are thrilled to introduce **Qwen-Image**, an image generation foundation model in the Qwen series that achieves significant breakthroughs in **complex text rendering** and **precise image editing**.

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ğŸ¯ Core Advantages</strong><br>
  Experiments demonstrate that this model possesses powerful general capabilities in image generation and editing, with particularly outstanding performance in text rendering, especially for Chinese characters.
</div>

</div>

## ğŸ”§ Technical Specifications

<div style="overflow-x: auto; margin: 16px 0;">
<table style="width: 100%; border-collapse: collapse; background: white; border-radius: 6px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
  <thead style="background: #f8fafc;">
    <tr>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Specification</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Details</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Model Type</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Text-to-Image Generation (T2I)</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Architecture</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Diffusion Transformer</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Supported Resolutions</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Multiple aspect ratios (1:1, 16:9, 9:16, 4:3, 3:4, 3:2, 2:3)</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Maximum Resolution</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">1664Ã—928</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Inference Steps</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Recommended 50 steps</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">CFG Guidance</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">true_cfg_scale: 4.0</td>
    </tr>
    <tr>
      <td style="padding: 12px; font-weight: 500;">License</td>
      <td style="padding: 12px;">Apache 2.0</td>
    </tr>
  </tbody>
</table>
</div>

---

# ğŸš€ Quick Start
---

# ğŸ¨ ComfyUI Usage Guide

## ğŸŒ ComfyUI Web Interface Usage

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

### ğŸ“ Step 1: Access Interface
![img_3.png](img_3.png)
Access the ComfyUI interface through the service instance's access link

### ğŸ”§ Step 2: Load Workflow

Select the Qwen-Image dedicated workflow template and remove the Lora node configuration
[img_4.png](img_4.png)

### âœï¸ Step 3: Set Prompts

Fill in the description in the **TextEncode** node:

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">âœ… Positive Prompt</h4>
<p style="margin: 0; color: #065f46;">Describe the desired image content and style</p>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
<h4 style="color: #ea580c; margin: 0 0 8px 0;">âŒ Negative Prompt</h4>
<p style="margin: 0; color: #9a3412;">Content you don't want to generate</p>
</div>

</div>

### âš™ï¸ Step 4: Configure Parameters

Set image resolution, inference steps, and other parameters

### ğŸ¬ Step 5: Execute Generation

Click the execute button to start image generation

</div>

---

## ğŸ”Œ API Integration

## ğŸ”‘ Authentication Setup

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">
<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
<h4 style="color: #2563eb; margin: 0 0 8px 0;">ğŸŒ Get Server Address</h4>
<p style="margin: 0 0 12px 0;">Record the ComfyUI server's access address</p>

![img_3.png](img_3.png)
</div>
<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
<h4 style="color: #ea580c; margin: 0 0 8px 0;">ğŸ” Get API Token</h4>
<p style="margin: 0 0 12px 0;">Obtain the access token from the top-right corner of ComfyUI interface</p>

![img_1.png](img_1.png)
</div>

</div>

## ğŸ’» Python API Integration Example

<details style="border: 2px solid #2563eb; border-radius: 12px; padding: 20px; margin: 20px 0; background: linear-gradient(145deg, #f8fafc, #eff6ff); box-shadow: 0 8px 16px rgba(37, 99, 235, 0.15);">
<summary style="font-weight: bold; font-size: 18px; color: white; cursor: pointer; padding: 16px; background: linear-gradient(135deg, #2563eb, #1e40af); border-radius: 8px; margin: -20px -20px 20px -20px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); transition: all 0.3s ease; display: flex; align-items: center; box-shadow: 0 4px 8px rgba(37, 99, 235, 0.3);">
ğŸ Click to expand complete Python API integration code
</summary>

```python
import requests
import json
import uuid
import time
import random
import os

# ğŸ”§ Configuration Parameters
COMFYUI_SERVER = "your-server-address"
COMFYUI_TOKEN = "your-api-token"

# ğŸ¯ Qwen-Image Model Files
UNET_MODEL = "qwen_image_fp8_e4m3fn.safetensors"
CLIP_MODEL = "qwen_2.5_vl_7b_fp8_scaled.safetensors"
VAE_MODEL = "qwen_image_vae.safetensors"

class QwenImageClient:
    def __init__(self, server=COMFYUI_SERVER, token=COMFYUI_TOKEN):
        self.base_url = f"http://{server}"
        self.token = token
        self.client_id = str(uuid.uuid4())
        self.headers = {
            "Content-Type": "application/json",
            **({"Authorization": f"Bearer {token}"} if token else {})
        }

    def generate_image(self, prompt, negative_prompt="", width=1328, height=1328, steps=20, cfg=2.5, shift=3.1, seed=None):
        """ğŸ¨ Generate Image"""
        if seed is None:
            seed = random.randint(1, 1000000000000000)
        
        workflow = {
            "3": {
                "inputs": {
                    "seed": seed,
                    "steps": steps,
                    "cfg": cfg,
                    "sampler_name": "euler",
                    "scheduler": "simple",
                    "denoise": 1,
                    "model": ["66", 0],
                    "positive": ["6", 0],
                    "negative": ["7", 0],
                    "latent_image": ["58", 0]
                },
                "class_type": "KSampler",
                "_meta": {
                    "title": "KSampler"
                }
            },
            "6": {
                "inputs": {
                    "text": prompt,
                    "clip": ["38", 0]
                },
                "class_type": "CLIPTextEncode",
                "_meta": {
                    "title": "CLIP Text Encode (Positive Prompt)"
                }
            },
            "7": {
                "inputs": {
                    "text": negative_prompt,
                    "clip": ["38", 0]
                },
                "class_type": "CLIPTextEncode",
                "_meta": {
                    "title": "CLIP Text Encode (Negative Prompt)"
                }
            },
            "8": {
                "inputs": {
                    "samples": ["3", 0],
                    "vae": ["39", 0]
                },
                "class_type": "VAEDecode",
                "_meta": {
                    "title": "VAE Decode"
                }
            },
            "37": {
                "inputs": {
                    "unet_name": UNET_MODEL,
                    "weight_dtype": "default"
                },
                "class_type": "UNETLoader",
                "_meta": {
                    "title": "Load Diffusion Model"
                }
            },
            "38": {
                "inputs": {
                    "clip_name": CLIP_MODEL,
                    "type": "qwen_image",
                    "device": "default"
                },
                "class_type": "CLIPLoader",
                "_meta": {
                    "title": "Load CLIP"
                }
            },
            "39": {
                "inputs": {
                    "vae_name": VAE_MODEL
                },
                "class_type": "VAELoader",
                "_meta": {
                    "title": "Load VAE"
                }
            },
            "58": {
                "inputs": {
                    "width": width,
                    "height": height,
                    "batch_size": 1
                },
                "class_type": "EmptySD3LatentImage",
                "_meta": {
                    "title": "EmptySD3LatentImage"
                }
            },
            "60": {
                "inputs": {
                    "filename_prefix": "qwen-image",
                    "images": ["8", 0]
                },
                "class_type": "SaveImage",
                "_meta": {
                    "title": "Save Image"
                }
            },
            "66": {
                "inputs": {
                    "shift": shift,
                    "model": ["37", 0]
                },
                "class_type": "ModelSamplingAuraFlow",
                "_meta": {
                    "title": "ModelSamplingAuraFlow"
                }
            }
        }

        print("ğŸ“¤ Submitting Qwen-Image generation task...")
        response = requests.post(
            f"{self.base_url}/prompt",
            headers=self.headers,
            json={"prompt": workflow, "client_id": self.client_id}
        )
        
        print(f"API Response: {response.text}")
        result = response.json()
        if "error" in result:
            raise Exception(f"Workflow error: {result['error']}")
        if "prompt_id" not in result:
            raise Exception(f"No prompt_id in response: {result}")
        
        return result["prompt_id"]

    def get_status(self, task_id):
        """ğŸ“Š Get Task Status"""
        try:
            # Check queue status
            queue_response = requests.get(f"{self.base_url}/queue", headers=self.headers)
            queue_data = queue_response.json()
            
            # Check if in running queue
            if any(item[1] == task_id for item in queue_data.get("queue_running", [])):
                return "processing"
            
            # Check if in pending queue
            if any(item[1] == task_id for item in queue_data.get("queue_pending", [])):
                return "pending"
            
            # Check history
            history_response = requests.get(f"{self.base_url}/history/{task_id}", headers=self.headers)
            if history_response.status_code == 200:
                history = history_response.json()
                if task_id in history:
                    return "completed"
            
            return "processing"
        except Exception as e:
            print(f"Status check error: {e}")
            return "processing"

    def download_image(self, task_id, output_path="qwen_image_output.png"):
        """ğŸ“¥ Download Generated Image"""
        try:
            response = requests.get(f"{self.base_url}/history/{task_id}", headers=self.headers)
            history = response.json()
            
            if task_id in history:
                outputs = history[task_id]['outputs']
                for node_id, output in outputs.items():
                    if 'images' in output:
                        for image_info in output['images']:
                            filename = image_info['filename']
                            image_response = requests.get(
                                f"{self.base_url}/view?filename={filename}",
                                headers=self.headers
                            )
                            
                            with open(output_path, "wb") as f:
                                f.write(image_response.content)
                            
                            return output_path
            
            return None
        except Exception as e:
            print(f"Download error: {e}")
            return None

def main():
    """ğŸš€ Main Function - Execute Qwen-Image Generation Task"""
    client = QwenImageClient()
    
    try:
        print("ğŸ¨ Starting Qwen-Image generation task...")
        
        # ğŸ¯ Example Prompt - Hong Kong Neon Street Scene
        prompt = '''A vibrant, warm neon-lit street scene in Hong Kong at the afternoon, with a mix of colorful Chinese and English signs glowing brightly. The atmosphere is lively, cinematic, and rain-washed with reflections on the pavement. The colors are vivid, full of pink, blue, red, and green hues. Crowded buildings with overlapping neon signs. 1980s Hong Kong style. Signs include:
"é¾é³³å†°å®¤" "é‡‘è¯ç‡’è‡˜" "HAPPY HAIR" "é´»é‹èŒ¶é¤å»³" "EASY BAR" "æ°¸ç™¼é­šè›‹ç²‰" "æ·»è¨˜ç²¥éºµ" "SUNSHINE MOTEL" "ç¾éƒ½é¤å®¤" "å¯Œè¨˜ç³–æ°´" "å¤ªå¹³é¤¨" "é›…èŠ³é«®å‹å±‹" "STAR KTV" "éŠ€æ²³å¨›æ¨‚åŸ" "ç™¾æ¨‚é–€èˆå»³" "BUBBLE CAFE" "è¬è±ªéº»é›€é¤¨" "CITY LIGHTS BAR" "ç‘ç¥¥é¦™ç‡­èŠ" "æ–‡è¨˜æ–‡å…·" "GOLDEN JADE HOTEL" "LOVELY BEAUTY" "åˆèˆˆç™¾è²¨" "èˆˆæ—ºé›»å™¨" And the background is warm yellow street and with all stores' lights on.'''
        
        negative_prompt = "low quality, blurry, distorted, bad anatomy, deformed text"
        
        print(f"ğŸ“ Prompt: {prompt[:100]}...")
        
        # ğŸ¨ Generate Image
        task_id = client.generate_image(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=1328,
            height=1328,
            steps=20,
            cfg=2.5,
            shift=3.1
        )
        
        print(f"ğŸ†” Task ID: {task_id}")
        
        # â³ Wait for completion
        while True:
            status = client.get_status(task_id)
            print(f"ğŸ“Š Current status: {status}")
            
            if status == "completed":
                print("âœ… Image generation completed!")
                break
            elif status == "failed":
                print("âŒ Image generation failed!")
                exit(1)
            
            time.sleep(10)
        
        # ğŸ“¥ Download image
        output_file = client.download_image(task_id, "qwen_image_hongkong.png")
        if output_file:
            print(f"ğŸ‰ Image downloaded successfully! Saved as: {output_file}")
        else:
            print("âŒ Image download failed")
    
    except Exception as e:
        print(f"âŒ Error: {e}")

# ğŸ¯ Preset Example Functions
def generate_text_examples():
    """ğŸ“ Generate Different Types of Text Rendering Examples"""
    client = QwenImageClient()
    
    examples = [
        {
            "name": "Coffee Shop Sign",
            "prompt": '''A cozy coffee shop entrance with a wooden chalkboard sign reading "Qwen Coffee â˜• é€šä¹‰å’–å•¡" in beautiful handwritten style. Below it shows "ä»Šæ—¥ç‰¹ä»· Today's Special: æ‹¿é“ Latte Â¥25". The scene has warm lighting and vintage atmosphere.''',
            "filename": "coffee_shop_sign.png"
        },
        {
            "name": "Math Formula Blackboard",
            "prompt": '''A university classroom blackboard with mathematical equations written in white chalk: "E=mcÂ²", "Ï€â‰ˆ3.14159265359", "âˆ«f(x)dx", "âˆ‘(n=1 to âˆ)", "âˆš(aÂ²+bÂ²)=c". The handwriting is clear and academic style.''',
            "filename": "math_blackboard.png"
        },
        {
            "name": "Bilingual Bookstore",
            "prompt": '''A traditional bookstore with bilingual signs: "ä¹¦é¦™é—¨ç¬¬ Book Paradise", "æ–°ä¹¦ä¸Šæ¶ New Arrivals", "æ–‡å­¦å°è¯´ Literature", "å†å²ä¼ è®° Biography", "å„¿ç«¥è¯»ç‰© Children's Books". Warm wooden shelves filled with books.''',
            "filename": "bilingual_bookstore.png"
        },
        {
            "name": "Japanese Ramen Shop",
            "prompt": '''A Japanese ramen shop with neon signs displaying: "ã‚‰ãƒ¼ã‚ã‚“ Ramen", "å‘³å™Œãƒ©ãƒ¼ãƒ¡ãƒ³ Miso Ramen Â¥800", "é†¤æ²¹ãƒ©ãƒ¼ãƒ¡ãƒ³ Shoyu Ramen Â¥750", "è±šéª¨ãƒ©ãƒ¼ãƒ¡ãƒ³ Tonkotsu Ramen Â¥850". Traditional red lanterns and warm lighting.''',
            "filename": "ramen_shop_signs.png"
        }
    ]
    
    for example in examples:
        try:
            print(f"\nğŸ¨ Generating example: {example['name']}")
            task_id = client.generate_image(
                prompt=example['prompt'],
                negative_prompt="low quality, blurry, illegible text, distorted characters",
                width=1328,
                height=1328,
                steps=20,
                cfg=2.5
            )
            
            # Wait for completion
            while client.get_status(task_id) != "completed":
                time.sleep(5)
            
            # Download
            output_file = client.download_image(task_id, example['filename'])
            if output_file:
                print(f"âœ… {example['name']} generation completed: {output_file}")
            
        except Exception as e:
            print(f"âŒ {example['name']} generation failed: {e}")

if __name__ == "__main__":
    # Run main example
    main()
    
    # Optional: Run multiple text rendering examples
    # generate_text_examples()

```
</details>