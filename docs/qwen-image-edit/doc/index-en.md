<div style="background: linear-gradient(135deg, #2563eb, #1e40af); padding: 24px; border-radius: 8px; color: white; text-align: center; margin-bottom: 24px;">
  <h1 style="font-size: 2.5em; margin: 0; font-weight: 600;">✏️ Qwen-Image-Edit Image Editing</h1>
  <p style="font-size: 1.2em; margin: 16px 0 0 0; opacity: 0.9;">ComfyUI Native Workflow - Precise Text Editing with Dual Semantic & Appearance Control</p>
  <div style="margin-top: 20px;">
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">📝 Precise Text Editing</span>
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">🎨 Semantic & Appearance</span>
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">🌐 Multilingual</span>
  </div>
</div>

## 📋 Qwen-Image-Edit Model Overview

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

**Qwen-Image-Edit** is the image editing version of Qwen-Image. Built upon the 20B Qwen-Image model with further training, it successfully extends Qwen-Image's text rendering capabilities to editing tasks, supporting precise text editing. Additionally, Qwen-Image-Edit simultaneously inputs images to Qwen2.5-VL (for visual semantic control) and VAE Encoder (for visual appearance control), achieving dual semantic/appearance editing capabilities.

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #2563eb;">📝</div>
<h4 style="margin: 0 0 8px 0; color: #1e40af;">Precise Text Editing</h4>
<p style="margin: 0; color: #1e40af;">Supports Chinese and English text editing while preserving text size, font, and style</p>
</div>

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #059669;">🎨</div>
<h4 style="margin: 0 0 8px 0; color: #059669;">Dual Semantic & Appearance Editing</h4>
<p style="margin: 0; color: #065f46;">Supports both low-level visual appearance and high-level visual semantic editing</p>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #ea580c;">🏆</div>
<h4 style="margin: 0 0 8px 0; color: #ea580c;">SOTA Performance</h4>
<p style="margin: 0; color: #9a3412;">Achieves SOTA results across multiple public benchmarks as a powerful image generation foundation model</p>
</div>

</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>🔗 Official Resources</strong><br>
  • <strong>GitHub Repository</strong>: <a href="https://github.com/QwenLM/Qwen-Image" target="_blank" style="color: #2563eb;">QwenLM/Qwen-Image</a><br>
  • <strong>Hugging Face</strong>: <a href="https://huggingface.co/Qwen/Qwen-Image-Edit" target="_blank" style="color: #2563eb;">🤗 Qwen/Qwen-Image-Edit</a><br>
  • <strong>ModelScope</strong>: <a href="https://modelscope.cn/models/qwen/Qwen-Image-Edit" target="_blank" style="color: #2563eb;">ModelScope</a>
</div>

### 🎯 Core Editing Capabilities

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #fef3c7; border-left: 4px solid #d97706; padding: 16px; border-radius: 4px;">
<h4 style="color: #d97706; margin: 0 0 8px 0;">🔤 Low-Level Visual Appearance Editing</h4>
<ul style="margin: 0; padding-left: 20px; color: #9a3412;">
  <li>Style Transfer</li>
  <li>Image Addition/Deletion/Modification</li>
  <li>Color Adjustment</li>
  <li>Texture Modification</li>
</ul>
</div>

<div style="background: #f3e8ff; border-left: 4px solid #7c3aed; padding: 16px; border-radius: 4px;">
<h4 style="color: #7c3aed; margin: 0 0 8px 0;">🧠 High-Level Visual Semantic Editing</h4>
<ul style="margin: 0; padding-left: 20px; color: #5b21b6;">
  <li>IP Creation</li>
  <li>Object Rotation</li>
  <li>Scene Reconstruction</li>
  <li>Concept Replacement</li>
</ul>
</div>

</div>

</div>

## 🎥 ComfyOrg Qwen-Image-Edit Live Stream Replay

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

Watch the official live stream replay to learn detailed usage methods and best practices for Qwen-Image-Edit in ComfyUI.

<div style="text-align: center; margin: 20px 0;">
  <iframe style="width: 100%; aspect-ratio: 16/9; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" src="https://www.youtube.com/embed/TZIijn-tvoc?si=Vb-ZNwTvJC67_UEE" title="Qwen-Image Edit in ComfyUI - Image Editing Model / August 19th, 2025" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

</div>

## 🚀 Qwen-Image-Edit ComfyUI Native Workflow

### ⚠️ Environment Requirements

<div style="background: #fef3c7; border-left: 4px solid #d97706; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>📋 Pre-usage Checklist</strong><br>
  • Ensure ComfyUI is updated to the latest version<br>
  • Recommend using the latest development version (nightly) for full functionality<br>
  • The workflow in this guide can be found in ComfyUI's workflow templates<br>
  • If nodes are missing when loading the workflow, check ComfyUI version or node import status
</div>

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #dcfce7; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">📥 Download Links</h4>
<ul style="margin: 0; padding-left: 20px; color: #065f46;">
  <li><a href="https://www.comfy.org/download" target="_blank" style="color: #059669;">ComfyUI Download</a></li>
  <li><a href="/installation/update_comfyui" target="_blank" style="color: #059669;">ComfyUI Update Tutorial</a></li>
  <li><a href="/interface/features/template" target="_blank" style="color: #059669;">Workflow Templates</a></li>
</ul>
</div>

<div style="background: #fef2f2; border-left: 4px solid #dc2626; padding: 16px; border-radius: 4px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">🔧 Common Issues</h4>
<ul style="margin: 0; padding-left: 20px; color: #991b1b;">
  <li>Missing nodes: Version too old or import failed</li>
  <li>Incomplete features: Using stable version instead of dev version</li>
  <li>Loading failure: Node import exception during startup</li>
</ul>
</div>

</div>

### 📥 Step 1: Download Workflow Files

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

After updating ComfyUI, you can find the workflow files in templates, or drag the workflow below into ComfyUI to load it.

<div style="text-align: center; margin: 20px 0;">
  <img src="https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/image/qwen/qwen-image-edit/qwen_image_edit.png" alt="Qwen-Image-Edit Workflow" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
  <p style="margin: 8px 0 0 0; color: #64748b; font-size: 14px;">Click image to download, drag into ComfyUI to load workflow</p>
</div>

<div style="text-align: center; margin: 20px 0;">
  <a href="https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/image_qwen_image_edit.json" target="_blank" style="display: inline-block; background: linear-gradient(135deg, #2563eb, #1e40af); color: white; padding: 12px 24px; border-radius: 8px; text-decoration: none; font-weight: bold; box-shadow: 0 4px 8px rgba(37, 99, 235, 0.3);">
    📄 Download JSON Workflow File
  </a>
</div>

### 📁 Sample Input Image

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px; margin: 16px 0; text-align: center;">
<h4 style="color: #059669; margin: 0 0 12px 0;">🖼️ Sample Input Image</h4>
<img src="https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/image/qwen/qwen-image-edit/input.png" alt="Sample Input Image" style="max-width: 400px; border-radius: 6px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
<p style="margin: 8px 0 0 0; color: #065f46; font-size: 13px;">Right-click to save image for workflow testing</p>
</div>

</div>

### 🔗 Step 2: Download Model Files

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

All model files can be found at <a href="https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main" target="_blank" style="color: #2563eb;">Comfy-Org/Qwen-Image_ComfyUI</a> or <a href="https://huggingface.co/Comfy-Org/Qwen-Image-Edit_ComfyUI" target="_blank" style="color: #2563eb;">Comfy-Org/Qwen-Image-Edit_ComfyUI</a>.

#### 📂 Model File Structure

<div style="background: #1e293b; border-radius: 6px; padding: 16px; margin: 16px 0;">
<pre style="margin: 0; color: #e2e8f0; font-family: 'Courier New', monospace; font-size: 14px;"><code>📂 ComfyUI/
├── 📂 models/
│   ├── 📂 diffusion_models/
│   │   └── qwen_image_edit_fp8_e4m3fn.safetensors
│   ├── 📂 loras/
│   │   └── Qwen-Image-Lightning-4steps-V1.0.safetensors
│   ├── 📂 vae/
│   │   └── qwen_image_vae.safetensors
│   └── 📂 text_encoders/
│       └── qwen_2.5_vl_7b_fp8_scaled.safetensors</code></pre>
</div>

#### 🔽 Model Download Links

<div style="overflow-x: auto; margin: 16px 0;">
<table style="width: 100%; border-collapse: collapse; background: white; border-radius: 6px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
  <thead style="background: #f8fafc;">
    <tr>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Model Type</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">File Name</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">🧠 Diffusion Model</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-family: monospace; font-size: 12px;">
        <a href="https://huggingface.co/Comfy-Org/Qwen-Image-Edit_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_edit_fp8_e4m3fn.safetensors" target="_blank" style="color: #2563eb;">qwen_image_edit_fp8_e4m3fn.safetensors</a>
      </td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Main image editing diffusion model</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">⚡ LoRA</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-family: monospace; font-size: 12px;">
        <a href="https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors" target="_blank" style="color: #2563eb;">Qwen-Image-Lightning-4steps-V1.0.safetensors</a>
      </td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">4-step acceleration LoRA (optional)</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">📝 Text Encoder</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-family: monospace; font-size: 12px;">
        <a href="https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors" target="_blank" style="color: #2563eb;">qwen_2.5_vl_7b_fp8_scaled.safetensors</a>
      </td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Qwen2.5-VL text encoder</td>
    </tr>
    <tr>
      <td style="padding: 12px; font-weight: 500;">🎨 VAE</td>
      <td style="padding: 12px; font-family: monospace; font-size: 12px;">
        <a href="https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors" target="_blank" style="color: #2563eb;">qwen_image_vae.safetensors</a>
      </td>
      <td style="padding: 12px;">Variational autoencoder</td>
    </tr>
  </tbody>
</table>
</div>

</div>

### 🔧 Step 3: Workflow Configuration Operations

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<div style="text-align: center; margin: 20px 0;">
  <img src="https://mintcdn.com/dripart/SIDaLac8vBogzwm7/images/tutorial/image/qwen/qwen_image_edit.jpg?fit=max&auto=format&n=SIDaLac8vBogzwm7&q=85&s=98a706bfa8f1578a4dfd7f2a0a415926" alt="Qwen-Image-Edit Workflow Configuration Steps" style="width: 100%; max-width: 1200px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
</div>

#### 📋 Detailed Configuration Steps

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
<h4 style="color: #2563eb; margin: 0 0 8px 0;">🔧 Model Loading</h4>
<ul style="margin: 0; padding-left: 20px; color: #1e40af; font-size: 14px;">
  <li><strong>Load Diffusion Model</strong>:<br><code>qwen_image_edit_fp8_e4m3fn.safetensors</code></li>
  <li><strong>Load CLIP</strong>:<br><code>qwen_2.5_vl_7b_fp8_scaled.safetensors</code></li>
  <li><strong>Load VAE</strong>:<br><code>qwen_image_vae.safetensors</code></li>
</ul>
</div>

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">📁 Image Loading</h4>
<p style="margin: 0; color: #065f46; font-size: 14px;">Upload the image to be edited in the <strong>Load Image</strong> node</p>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
<h4 style="color: #ea580c; margin: 0 0 8px 0;">📝 Prompt Settings</h4>
<p style="margin: 0; color: #9a3412; font-size: 14px;">Set editing prompts in the <strong>CLIP Text Encoder</strong> node</p>
</div>

</div>

#### ⚙️ Advanced Configuration Options

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #fef3c7; border-left: 4px solid #d97706; padding: 16px; border-radius: 4px;">
<h4 style="color: #d97706; margin: 0 0 8px 0;">📐 Image Size Processing</h4>
<p style="margin: 0 0 8px 0; color: #9a3412; font-size: 14px;">The <strong>Scale Image to Total Pixels</strong> node scales input images to one million total pixels</p>
<ul style="margin: 0; padding-left: 20px; color: #9a3412; font-size: 13px;">
  <li>Prevents quality loss from oversized inputs (e.g., 2048×2048)</li>
  <li>Use <strong>Ctrl+B</strong> to bypass if you know your input image size</li>
</ul>
</div>

<div style="background: #f3e8ff; border-left: 4px solid #7c3aed; padding: 16px; border-radius: 4px;">
<h4 style="color: #7c3aed; margin: 0 0 8px 0;">⚡ Lightning LoRA Acceleration</h4>
<p style="margin: 0 0 8px 0; color: #5b21b6; font-size: 14px;">Use 4-step Lightning LoRA for faster image generation</p>
<ul style="margin: 0; padding-left: 20px; color: #5b21b6; font-size: 13px;">
  <li>Select the <strong>LoraLoaderModelOnly</strong> node</li>
  <li>Press <strong>Ctrl+B</strong> to enable the node</li>
</ul>
</div>

</div>

#### 🎛️ KSampler Parameter Tuning

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>🔧 KSampler Node Parameter Settings</strong><br>
  For <code>steps</code> and <code>cfg</code> settings, the workflow provides parameter suggestion notes below the node for testing optimal settings:<br>
  • <strong>Steps</strong>: Recommended 20-50 steps<br>
  • <strong>CFG</strong>: Recommended 3.5-7.5<br>
  • <strong>Sampler</strong>: Recommended DPM++ 2M Karras
</div>

#### 🚀 Execute Generation

<div style="text-align: center; margin: 20px 0;">
  <div style="background: linear-gradient(135deg, #059669, #047857); color: white; padding: 16px 32px; border-radius: 8px; display: inline-block; box-shadow: 0 4px 8px rgba(5, 150, 105, 0.3);">
    <strong>⌨️ Click Queue button or use shortcut Ctrl(Cmd) + Enter to run workflow</strong>
  </div>
</div>

</div>

## API Execute
<details style="border: 2px solid #2563eb; border-radius: 12px; padding: 20px; margin: 20px 0; background: linear-gradient(145deg, #f8fafc, #eff6ff); box-shadow: 0 8px 16px rgba(37, 99, 235, 0.15);">
<summary style="font-weight: bold; font-size: 18px; color: white; cursor: pointer; padding: 16px; background: linear-gradient(135deg, #2563eb, #1e40af); border-radius: 8px; margin: -20px -20px 20px -20px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); transition: all 0.3s ease; display: flex; align-items: center; box-shadow: 0 4px 8px rgba(37, 99, 235, 0.3);">
📋 ComfyUI API Python
</summary>

```python

import requests
import json
import uuid
import time
import random
import os

# Configuration Parameters - Qwen Image Edit Specific
COMFYUI_SERVER = "127.0.0.1:8188"  # Local server
COMFYUI_TOKEN = ""  # Usually no token needed for local

# Model Configuration
UNET_MODEL = "qwen_image_edit_fp8_e4m3fn.safetensors"
CLIP_MODEL = "qwen_2.5_vl_7b_fp8_scaled.safetensors"
VAE_MODEL = "qwen_image_vae.safetensors"

# Default Parameters
DEFAULT_EDIT_PROMPT = "Remove all UI text elements from the image. Keep the feeling that the characters and scene are in water. Also, remove the green UI elements at the bottom."
DEFAULT_NEGATIVE_PROMPT = ""
DEFAULT_INPUT_IMAGE = "Qwen-Image_00043_.png"

class ComfyUIQwenImageEditClient:
    def __init__(self, server=COMFYUI_SERVER, token=COMFYUI_TOKEN):
        self.base_url = f"http://{server}"
        self.token = token
        self.client_id = str(uuid.uuid4())
        self.headers = {"Content-Type": "application/json"}
        if token:
            self.headers["Authorization"] = f"Bearer {token}"

    def upload_image(self, image_path):
        """Upload image to ComfyUI server"""
        try:
            with open(image_path, 'rb') as f:
                files = {'image': f}
                response = requests.post(f"{self.base_url}/upload/image", files=files)
                if response.status_code == 200:
                    result = response.json()
                    return result.get('name', os.path.basename(image_path))
                else:
                    raise Exception(f"Failed to upload image: {response.text}")
        except Exception as e:
            print(f"Image upload error: {e}")
            return None

    def edit_image_with_qwen(self, edit_prompt, input_image_path=None, 
                            input_image_name=None, negative_prompt="",
                            steps=20, cfg=2.5, seed=None, shift=3.0,
                            cfg_norm_strength=1.0, megapixels=1.0,
                            upscale_method="lanczos"):
        """Edit image using Qwen Image Edit model based on original JSON workflow"""
        print("Starting Qwen Image Edit generation...")
        
        # Generate random seed if not provided
        if seed is None:
            seed = random.randint(1, 1000000000000000)

        # Handle input image
        if input_image_path and not input_image_name:
            input_image_name = self.upload_image(input_image_path)
            if not input_image_name:
                raise Exception("Failed to upload input image")
        elif not input_image_name:
            input_image_name = DEFAULT_INPUT_IMAGE

        # Workflow based on your provided JSON
        workflow = {
            "3": {
                "inputs": {
                    "seed": seed,
                    "steps": steps,
                    "cfg": cfg,
                    "sampler_name": "euler",
                    "scheduler": "simple",
                    "denoise": 1,
                    "model": ["75", 0],
                    "positive": ["76", 0],
                    "negative": ["77", 0],
                    "latent_image": ["88", 0]
                },
                "class_type": "KSampler",
                "_meta": {"title": "K Sampler"}
            },
            "8": {
                "inputs": {
                    "samples": ["3", 0],
                    "vae": ["39", 0]
                },
                "class_type": "VAEDecode",
                "_meta": {"title": "VAE Decode"}
            },
            "37": {
                "inputs": {
                    "unet_name": UNET_MODEL,
                    "weight_dtype": "default"
                },
                "class_type": "UNETLoader",
                "_meta": {"title": "UNet Loader"}
            },
            "38": {
                "inputs": {
                    "clip_name": CLIP_MODEL,
                    "type": "qwen_image",
                    "device": "default"
                },
                "class_type": "CLIPLoader",
                "_meta": {"title": "CLIP Loader"}
            },
            "39": {
                "inputs": {
                    "vae_name": VAE_MODEL
                },
                "class_type": "VAELoader",
                "_meta": {"title": "VAE Loader"}
            },
            "60": {
                "inputs": {
                    "filename_prefix": "qwen_image_edit",
                    "images": ["8", 0]
                },
                "class_type": "SaveImage",
                "_meta": {"title": "Save Image"}
            },
            "66": {
                "inputs": {
                    "shift": shift,
                    "model": ["37", 0]
                },
                "class_type": "ModelSamplingAuraFlow",
                "_meta": {"title": "Model Sampling AuraFlow"}
            },
            "75": {
                "inputs": {
                    "strength": cfg_norm_strength,
                    "model": ["66", 0]
                },
                "class_type": "CFGNorm",
                "_meta": {"title": "CFG Norm"}
            },
            "76": {
                "inputs": {
                    "prompt": edit_prompt,
                    "clip": ["38", 0],
                    "vae": ["39", 0],
                    "image": ["93", 0]
                },
                "class_type": "TextEncodeQwenImageEdit",
                "_meta": {"title": "Text Encode Qwen Image Edit (Positive)"}
            },
            "77": {
                "inputs": {
                    "prompt": negative_prompt,
                    "clip": ["38", 0],
                    "vae": ["39", 0],
                    "image": ["93", 0]
                },
                "class_type": "TextEncodeQwenImageEdit",
                "_meta": {"title": "Text Encode Qwen Image Edit (Negative)"}
            },
            "78": {
                "inputs": {
                    "image": input_image_name
                },
                "class_type": "LoadImage",
                "_meta": {"title": "Load Input Image"}
            },
            "88": {
                "inputs": {
                    "pixels": ["93", 0],
                    "vae": ["39", 0]
                },
                "class_type": "VAEEncode",
                "_meta": {"title": "VAE Encode"}
            },
            "93": {
                "inputs": {
                    "upscale_method": upscale_method,
                    "megapixels": megapixels,
                    "image": ["78", 0]
                },
                "class_type": "ImageScaleToTotalPixels",
                "_meta": {"title": "Image Scale To Total Pixels"}
            }
        }

        print("Submitting Qwen Image Edit workflow...")
        print(f"Edit Prompt: {edit_prompt}")
        print(f"Input Image: {input_image_name}")
        print(f"Steps: {steps}")
        print(f"CFG: {cfg}")
        print(f"Seed: {seed}")
        print(f"Megapixels: {megapixels}")
        print(f"Upscale Method: {upscale_method}")
        
        response = requests.post(
            f"{self.base_url}/prompt", 
            headers=self.headers, 
            json={"prompt": workflow, "client_id": self.client_id}
        )
        
        print(f"API Response: {response.text}")

        if response.status_code != 200:
            raise Exception(f"API request failed with status code: {response.status_code}")

        result = response.json()
        if "error" in result:
            raise Exception(f"Workflow error: {result['error']}")
        if "prompt_id" not in result:
            raise Exception(f"No prompt_id in response: {result}")
        
        return result["prompt_id"], seed

    def get_status(self, task_id):
        """Get task status"""
        try:
            # Check queue status
            queue_data = requests.get(f"{self.base_url}/queue", headers=self.headers).json()
            
            # Check if in running queue
            if any(item[1] == task_id for item in queue_data.get("queue_running", [])):
                return "processing"
            
            # Check if in pending queue
            if any(item[1] == task_id for item in queue_data.get("queue_pending", [])):
                return "pending"
            
            # Check history
            history_response = requests.get(f"{self.base_url}/history/{task_id}", headers=self.headers)
            if history_response.status_code == 200:
                history = history_response.json()
                if task_id in history:
                    return "completed"
            
            return "processing"
        except Exception as e:
            print(f"Status check error: {e}")
            return "processing"

    def download_image(self, task_id, output_dir="outputs"):
        """Download generated images"""
        try:
            # Ensure output directory exists
            os.makedirs(output_dir, exist_ok=True)
            
            response = requests.get(f"{self.base_url}/history/{task_id}", headers=self.headers)
            history = response.json()
            
            if task_id in history:
                outputs = history[task_id]['outputs']
                downloaded_files = []
                
                for node_id, output in outputs.items():
                    if 'images' in output:
                        for img_info in output['images']:
                            filename = img_info['filename']
                            # Download image
                            img_response = requests.get(
                                f"{self.base_url}/view?filename={filename}", 
                                headers=self.headers
                            )
                            
                            if img_response.status_code == 200:
                                output_path = os.path.join(output_dir, filename)
                                with open(output_path, "wb") as f:
                                    f.write(img_response.content)
                                downloaded_files.append(output_path)
                                print(f"Image saved: {output_path}")
                
                return downloaded_files
                
        except Exception as e:
            print(f"Download error: {e}")
        
        return []

    def generate_batch(self, edit_configs, **kwargs):
        """Batch edit images with different configurations"""
        results = []
        
        for i, config in enumerate(edit_configs):
            print(f"\nStarting image edit task {i+1}/{len(edit_configs)}...")
            
            try:
                task_id, seed = self.edit_image_with_qwen(**config, **kwargs)
                
                # Wait for completion
                while True:
                    status = self.get_status(task_id)
                    print(f"Task {i+1} status: {status}")
                    
                    if status == "completed":
                        files = self.download_image(task_id)
                        results.append({
                            'task_id': task_id,
                            'seed': seed,
                            'files': files,
                            'config': config
                        })
                        break
                    elif status == "failed":
                        print(f"Task {i+1} failed")
                        break
                    
                    time.sleep(5)
                    
            except Exception as e:
                print(f"Task {i+1} error: {e}")
        
        return results

    def edit_with_quality_presets(self, edit_prompt, input_image_path, 
                                 quality_preset="high"):
        """Edit image with predefined quality settings"""
        quality_presets = {
            "fast": {
                "steps": 10,
                "cfg": 2.0,
                "megapixels": 0.5,
                "upscale_method": "nearest-exact"
            },
            "balanced": {
                "steps": 15,
                "cfg": 2.5,
                "megapixels": 1.0,
                "upscale_method": "bilinear"
            },
            "high": {
                "steps": 20,
                "cfg": 3.0,
                "megapixels": 1.5,
                "upscale_method": "lanczos"
            },
            "ultra": {
                "steps": 30,
                "cfg": 3.5,
                "megapixels": 2.0,
                "upscale_method": "lanczos"
            }
        }
        
        settings = quality_presets.get(quality_preset, quality_presets["high"])
        return self.edit_image_with_qwen(
            edit_prompt=edit_prompt,
            input_image_path=input_image_path,
            **settings
        )

    def generate_edit_variations(self, base_image_path, edit_prompts):
        """Generate multiple edit variations of the same image"""
        results = []
        
        for i, prompt in enumerate(edit_prompts):
            print(f"\nGenerating edit variation {i+1}: {prompt[:50]}...")
            
            try:
                task_id, seed = self.edit_image_with_qwen(
                    edit_prompt=prompt,
                    input_image_path=base_image_path
                )
                
                # Wait for completion
                while True:
                    status = self.get_status(task_id)
                    if status == "completed":
                        files = self.download_image(task_id)
                        results.append({
                            'prompt': prompt,
                            'files': files,
                            'seed': seed
                        })
                        break
                    elif status == "failed":
                        print(f"Edit variation {i+1} failed")
                        break
                    time.sleep(5)
                    
            except Exception as e:
                print(f"Edit variation {i+1} error: {e}")
        
        return results

def main():
    """Main function - Execute Qwen Image Edit"""
    client = ComfyUIQwenImageEditClient()
    
    try:
        print("Qwen Image Edit client started...")
        
        # Single image edit example
        print("\n=== Single Image Edit ===")
        
        # You can provide a local image path or use existing image name
        input_image_path = None  # Set to your image path, e.g., "input.jpg"
        
        task_id, seed = client.edit_image_with_qwen(
            edit_prompt=DEFAULT_EDIT_PROMPT,
            input_image_path=input_image_path,
            input_image_name=DEFAULT_INPUT_IMAGE,
            negative_prompt=DEFAULT_NEGATIVE_PROMPT,
            steps=20,
            cfg=2.5,
            shift=3.0,
            megapixels=1.0,
            upscale_method="lanczos"
        )
        
        print(f"Task ID: {task_id}")
        print(f"Seed: {seed}")

        # Wait for task completion
        while True:
            status = client.get_status(task_id)
            print(f"Current status: {status}")
            
            if status == "completed":
                print("Image edit completed!")
                break
            elif status == "failed":
                print("Edit failed!")
                return
            
            time.sleep(5)

        # Download edited images
        downloaded_files = client.download_image(task_id)
        if downloaded_files:
            print(f"Successfully downloaded {len(downloaded_files)} files!")
            for file in downloaded_files:
                print(f"File path: {file}")
        else:
            print("Download failed")

        # Quality preset example
        print("\n=== Quality Preset Example ===")
        # Uncomment to test different quality settings
        # if input_image_path:
        #     for preset in ["fast", "balanced", "high"]:
        #         print(f"Editing with {preset} quality...")
        #         task_id, seed = client.edit_with_quality_presets(
        #             "Remove background and make it white", input_image_path, preset
        #         )
        #         # Wait and download logic here...

        # Edit variations example
        print("\n=== Edit Variations Example ===")
        edit_variations = [
            "Remove all text and UI elements from the image",
            "Change the background to a sunset sky",
            "Make the image black and white",
            "Add more vibrant colors to the scene",
            "Remove people from the image"
        ]
        
        # Uncomment to run edit variations
        # if input_image_path:
        #     variation_results = client.generate_edit_variations(input_image_path, edit_variations)
        #     print(f"Generated {len(variation_results)} edit variations")

        # Batch edit example
        print("\n=== Batch Edit Example ===")
        batch_configs = [
            {
                'edit_prompt': "Remove all UI elements and make background transparent",
                'input_image_name': DEFAULT_INPUT_IMAGE,
                'steps': 15,
                'cfg': 2.0
            },
            {
                'edit_prompt': "Change the lighting to golden hour",
                'input_image_name': DEFAULT_INPUT_IMAGE,
                'steps': 20,
                'cfg': 2.5
            }
        ]
        
        # Uncomment to run batch editing
        # batch_results = client.generate_batch(batch_configs, megapixels=1.0)
        # print(f"Batch editing completed, processed {len(batch_results)} images")

    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    main()


```

</details>


## 🎯 Editing Application Scenarios

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #2563eb;">📝</div>
<h4 style="margin: 0 0 8px 0; color: #1e40af;">Text Editing</h4>
<p style="margin: 0; color: #1e40af;">Poster text modification, logo replacement, multilingual localization</p>
</div>

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #059669;">🎨</div>
<h4 style="margin: 0 0 8px 0; color: #059669;">Style Transfer</h4>
<p style="margin: 0; color: #065f46;">Artistic style transfer, tone adjustment, visual effect enhancement</p>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #ea580c;">🏢</div>
<h4 style="margin: 0 0 8px 0; color: #ea580c;">Commercial Applications</h4>
<p style="margin: 0; color: #9a3412;">Product image editing, advertising material creation, brand visual consistency</p>
</div>

<div style="background: #f5f3ff; border-left: 4px solid #7c3aed; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #7c3aed;">🎭</div>
<h4 style="margin: 0 0 8px 0; color: #7c3aed;">Creative Design</h4>
<p style="margin: 0; color: #5b21b6;">Concept art creation, IP character design, scene reconstruction</p>
</div>

</div>

## 💡 Usage Tips and Recommendations

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #dcfce7; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">✅ Best Practices</h4>
<ul style="margin: 0; padding-left: 20px; color: #065f46;">
  <li>Use clear, specific editing instructions</li>
  <li>Maintain appropriate input image quality and resolution</li>
  <li>Describe specific font and style requirements for text editing</li>
  <li>Use Lightning LoRA for quick previews</li>
</ul>
</div>

<div style="background: #fef2f2; border-left: 4px solid #dc2626; padding: 16px; border-radius: 4px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">⚠️ Important Notes</h4>
<ul style="margin: 0; padding-left: 20px; color: #991b1b;">
  <li>Avoid oversized input images that affect generation quality</li>
  <li>Complex editing tasks may require multiple iterations</li>
  <li>Text editing effectiveness depends on original text clarity</li>
  <li>Set CFG values reasonably to avoid overfitting</li>
</ul>
</div>

</div>

## 🔧 Technical Specifications

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

### 💻 System Requirements

<div style="overflow-x: auto; margin: 16px 0;">
<table style="width: 100%; border-collapse: collapse; background: white; border-radius: 6px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
  <thead style="background: #f8fafc;">
    <tr>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Component</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Minimum</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Recommended</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">GPU VRAM</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">12GB</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">16GB+</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">System RAM</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">16GB</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">32GB+</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Storage Space</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">20GB</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">50GB+ SSD</td>
    </tr>
    <tr>
      <td style="padding: 12px; font-weight: 500;">Recommended GPU</td>
      <td style="padding: 12px;">RTX 4060 Ti</td>
      <td style="padding: 12px;">RTX 4080 / RTX 4090</td>
    </tr>
  </tbody>
</table>
</div>

### 🎨 Supported Editing Types

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 12px; margin: 16px 0;">
  <div style="background: #eff6ff; padding: 12px; border-radius: 6px; text-align: center;">
    <span style="background: #2563eb; color: white; padding: 4px 12px; border-radius: 12px; font-size: 12px;">Text Editing</span>
  </div>
  <div style="background: #f0fdf4; padding: 12px; border-radius: 6px; text-align: center;">
    <span style="background: #059669; color: white; padding: 4px 12px; border-radius: 12px; font-size: 12px;">Style Transfer</span>
  </div>
  <div style="background: #fff7ed; padding: 12px; border-radius: 6px; text-align: center;">
    <span style="background: #ea580c; color: white; padding: 4px 12px; border-radius: 12px; font-size: 12px;">Object Replacement</span>
  </div>
  <div style="background: #f3e8ff; padding: 12px; border-radius: 6px; text-align: center;">
    <span style="background: #7c3aed; color: white; padding: 4px 12px; border-radius: 12px; font-size: 12px;">Scene Reconstruction</span>
  </div>
  <div style="background: #fef3c7; padding: 12px; border-radius: 6px; text-align: center;">
    <span style="background: #d97706; color: white; padding: 4px 12px; border-radius: 12px; font-size: 12px;">Color Adjustment</span>
  </div>
  <div style="background: #fef2f2; padding: 12px; border-radius: 6px; text-align: center;">
    <span style="background: #dc2626; color: white; padding: 4px 12px; border-radius: 12px; font-size: 12px;">Texture Modification</span>
  </div>
</div>

### 🌐 Language Support

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
<strong>🔤 Text Editing Support</strong><br>
<p style="margin: 8px 0 0 0; color: #1e40af; font-size: 14px;">Precise editing and replacement of Chinese and English text</p>
</div>

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<strong>💬 Instruction Language</strong><br>
<p style="margin: 8px 0 0 0; color: #065f46; font-size: 14px;">Supports Chinese and English editing instructions, understands complex editing requirements</p>
</div>

</div>

</div>

### 🎯 Performance Benchmarks

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
<strong>🏆 SOTA Results</strong><br>
<p style="margin: 8px 0 0 0; color: #1e40af; font-size: 14px;">Achieves state-of-the-art performance across multiple public benchmarks</p>
</div>

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<strong>⚡ Generation Speed</strong><br>
<p style="margin: 8px 0 0 0; color: #065f46; font-size: 14px;">4-step Lightning LoRA enables 5x faster generation with minimal quality loss</p>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
<strong>🎯 Editing Precision</strong><br>
<p style="margin: 8px 0 0 0; color: #9a3412; font-size: 14px;">Maintains original text style, font, and size during precise text editing</p>
</div>

</div>

</div>

</div>

---

<div style="text-align: center; padding: 16px; background: #f8fafc; border-radius: 6px; margin-top: 24px;">
  <p style="margin: 0; color: #64748b; font-size: 14px;">
    ✏️ <strong>Qwen-Image-Edit Image Editing</strong> | Perfect Combination of Precise Text Editing and Dual Semantic & Appearance Control
  </p>
  <p style="margin: 4px 0 0 0; color: #94a3b8; font-size: 12px;">
    © 2025 Alibaba Qwen Team | Open Source License | Making Image Editing Intelligent and Efficient
  </p>
</div>