## Introduction
DeepSeek-R1 is a large language model (LLM) developed by Hangzhou DeepSeek Company, specifically optimized for tasks such as mathematics, coding, and logical reasoning. It employs advanced technologies like Mixture of Experts (MoE) and Multi-head Latent Attention (MLA), boasting 671 billion parameters and supporting input contexts of up to 128,000 tokens. DeepSeek-R1 aims to match or surpass the performance of OpenAI's o1 model in reasoning tasks.

- **Strong Reasoning Ability**: DeepSeek-R1 excels in tasks such as mathematics, code generation, and natural language reasoning, even surpassing similar models.

- **MoE Architecture**: Utilizes a Mixture of Experts model, employing numerous experts in each layer to process different inputs, thereby enhancing reasoning capabilities.

- **Long Context Support**: Can handle longer input contexts (128,000 tokens), which is crucial for complex reasoning tasks.

- **Fully Open Source**: DeepSeek Company has completely open-sourced DeepSeek-R1's training techniques and model weights, allowing developers to conduct further exploration and research.

- **Open Source Distilled Models**: DeepSeek R1 has generated six smaller models (such as Qwen2.5 and Llama3.1) for community use through distillation technology.


## üìñ User Guide

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>üí° Quick Start</strong><br>
  After completing the model deployment, you can view the model usage instructions on the Computing Nest service instance overview page, which provides API call examples, internal network access addresses, public network access addresses, and ApiKey.
</div>

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">
  <div style="text-align: center; margin-bottom: 16px;">
    <img src="../image-en/img-llm-use-desc.png" alt="Model usage instructions interface" style="max-width: 100%; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
  </div>
</div>

### üîå API Call Methods

#### üñ•Ô∏è Curl Command Call

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<div style="text-align: center; margin-bottom: 16px;">
  <img src="../image-en/img-api-call.png" alt="API call example" style="max-width: 100%; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>üìã Parameter Description</strong><br>
  ‚Ä¢ <code>${ServerIP}</code>: IP address from internal or public network address<br>
  ‚Ä¢ <code>${ApiKey}</code>: ApiKey provided on the page<br>
  ‚Ä¢ <code>${ModelName}</code>: Model name
</div>

Curl command calls can directly use the API call examples from the service instance overview page. The specific structure for calling the model API is as follows:

```bash
curl -X Post http://${ServerIP}:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer ${ApiKey}" \
  -d '{
    "model": "${ModelName}",
    "messages": [
      {
        "role": "user",
        "content": "Write a letter to my daughter from the future year 2035, telling her to study technology well, become the master of technology, and promote technological and economic development; she is currently in 3rd grade"
      }
    ]
  }'
```

</div>

#### üêç Python SDK Call

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>‚öôÔ∏è Configuration Instructions</strong><br>
  ‚Ä¢ <code>${ApiKey}</code>: Fill in the ApiKey from the page<br>
  ‚Ä¢ <code>${ServerUrl}</code>: Fill in the public or internal network address from the page, must include <code>/v1</code>
</div>

The following is Python example code:

```python
from openai import OpenAI

##### API Configuration #####
openai_api_key = "${ApiKey}"
openai_api_base = "${ServerUrl}"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

models = client.models.list()
model = models.data[0].id
print(model)


def main():
    stream = True

    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "Hello, please introduce yourself in as much detail as possible.",
                    }
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=stream,
    )

    if stream:
        for chunk in chat_completion:
            print(chunk.choices[0].delta.content, end="")
    else:
        result = chat_completion.choices[0].message.content
        print(result)


if __name__ == "__main__":
    main()
```

</div>