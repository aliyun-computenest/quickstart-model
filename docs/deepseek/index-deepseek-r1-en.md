<div style="background: linear-gradient(135deg, #2563eb, #1e40af); padding: 24px; border-radius: 8px; color: white; text-align: center; margin-bottom: 24px;">
  <h2 style="margin: 0; color: white;">🧠 DeepSeek-R1 Reasoning Model</h2>
  <p style="margin: 8px 0 0 0; opacity: 0.9;">671 Billion Parameter Reasoning Expert - Open Source Challenger to OpenAI o1</p>
</div>

## 🎯 Product Overview

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

DeepSeek-R1 is a large language model (LLM) developed by Hangzhou DeepSeek Company, specifically optimized for tasks such as mathematics, coding, and logical reasoning. It adopts advanced technologies including Mixture of Experts (MoE) and Multi-Head Latent Attention (MLA), with **671 billion parameters** and support for input contexts up to **128,000 tokens**.

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>🎯 Core Objective</strong><br>
  DeepSeek-R1 aims to match or exceed the performance of OpenAI's o1 model in reasoning tasks, providing world-class reasoning capabilities to the open source community.
</div>

</div>

## ✨ Core Features

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
  <strong>🚀 Powerful Reasoning Capabilities</strong><br>
  Outstanding performance in mathematics, code generation, and natural language reasoning tasks, even surpassing similar models, demonstrating excellent logical thinking abilities.
</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
  <strong>⚡ MoE Architecture Advantages</strong><br>
  Adopts mixture of experts model, using numerous experts in each layer to handle different inputs, significantly improving reasoning capabilities and processing efficiency.
</div>

<div style="background: #fef7ff; border-left: 4px solid #a855f7; padding: 16px; border-radius: 4px;">
  <strong>📚 Long Context Support</strong><br>
  Can handle longer input contexts (128,000 tokens), which is crucial for complex reasoning tasks and long document analysis.
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
  <strong>🔓 Fully Open Source</strong><br>
  DeepSeek Company has completely open-sourced DeepSeek-R1's training techniques and model weights, enabling developers to conduct further exploration and research.
</div>

<div style="background: #ecfdf5; border-left: 4px solid #10b981; padding: 16px; border-radius: 4px;">
  <strong>🎓 Open Source Distilled Models</strong><br>
  Through distillation techniques, generated 6 smaller models (such as Qwen2.5 and Llama3.1) for community use, lowering deployment barriers.
</div>

</div>

## 🎓 Distilled Model Ecosystem

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<h3 style="margin-top: 0; color: #1e40af;">📦 Open Source Distilled Model Series</h3>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>🎯 Distillation Strategy</strong><br>
  Through advanced distillation techniques, DeepSeek-R1's reasoning capabilities are transferred to smaller models, generating 6 lightweight versions for community use.
</div>

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 12px; margin: 16px 0;">

<div style="background: white; padding: 12px; border-radius: 6px; border: 1px solid #e2e8f0; text-align: center;">
  <div style="background: #dbeafe; color: #2563eb; padding: 6px 12px; border-radius: 4px; font-weight: 600; margin-bottom: 8px;">Qwen2.5 Series</div>
  <div style="color: #64748b; font-size: 14px;">High-performance distilled version</div>
</div>

<div style="background: white; padding: 12px; border-radius: 6px; border: 1px solid #e2e8f0; text-align: center;">
  <div style="background: #dcfce7; color: #059669; padding: 6px 12px; border-radius: 4px; font-weight: 600; margin-bottom: 8px;">Llama3.1 Series</div>
  <div style="color: #64748b; font-size: 14px;">Compatibility optimized version</div>
</div>

<div style="background: white; padding: 12px; border-radius: 6px; border: 1px solid #e2e8f0; text-align: center;">
  <div style="background: #fed7aa; color: #ea580c; padding: 6px 12px; border-radius: 4px; font-weight: 600; margin-bottom: 8px;">Lightweight Models</div>
  <div style="color: #64748b; font-size: 14px;">Edge deployment friendly</div>
</div>

<div style="background: white; padding: 12px; border-radius: 6px; border: 1px solid #e2e8f0; text-align: center;">
  <div style="background: #f3e8ff; color: #a855f7; padding: 6px 12px; border-radius: 4px; font-weight: 600; margin-bottom: 8px;">Customized Versions</div>
  <div style="color: #64748b; font-size: 14px;">Specific scenario optimization</div>
</div>

</div>

</div>

## 📖 User Guide

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>💡 Quick Start</strong><br>
  After completing the model deployment, you can view the model usage instructions on the Computing Nest service instance overview page, which provides API call examples, internal network access addresses, public network access addresses, and ApiKey.
</div>

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">
  <div style="text-align: center; margin-bottom: 16px;">
    <img src="../image-en/img-llm-use-desc.png" alt="Model usage instructions interface" style="max-width: 100%; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
  </div>
</div>

### 🔌 API Call Methods

#### 🖥️ Curl Command Call

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<div style="text-align: center; margin-bottom: 16px;">
  <img src="../image-en/img-api-call.png" alt="API call example" style="max-width: 100%; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>📋 Parameter Description</strong><br>
  • <code>${ServerIP}</code>: IP address from internal or public network address<br>
  • <code>${ApiKey}</code>: ApiKey provided on the page<br>
  • <code>${ModelName}</code>: Model name
</div>

Curl command calls can directly use the API call examples from the service instance overview page. The specific structure for calling the model API is as follows:

```bash
curl -X Post http://${ServerIP}:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer ${ApiKey}" \
  -d '{
    "model": "${ModelName}",
    "messages": [
      {
        "role": "user",
        "content": "Write a letter to my daughter from the future year 2035, telling her to study technology well, become the master of technology, and promote technological and economic development; she is currently in 3rd grade"
      }
    ]
  }'
```

</div>

#### 🐍 Python SDK Call

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>⚙️ Configuration Instructions</strong><br>
  • <code>${ApiKey}</code>: Fill in the ApiKey from the page<br>
  • <code>${ServerUrl}</code>: Fill in the public or internal network address from the page, must include <code>/v1</code>
</div>

The following is Python example code:

```python
from openai import OpenAI

##### API Configuration #####
openai_api_key = "${ApiKey}"
openai_api_base = "${ServerUrl}"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

models = client.models.list()
model = models.data[0].id
print(model)


def main():
    stream = True

    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "Hello, please introduce yourself in as much detail as possible.",
                    }
                ],
            }
        ],
        model=model,
        max_completion_tokens=1024,
        stream=stream,
    )

    if stream:
        for chunk in chat_completion:
            print(chunk.choices[0].delta.content, end="")
    else:
        result = chat_completion.choices[0].message.content
        print(result)


if __name__ == "__main__":
    main()
```

</div>

---

<div style="text-align: center; padding: 16px; background: #f8fafc; border-radius: 6px; margin-top: 24px;">
  <p style="margin: 0; color: #64748b; font-size: 14px;">
    🧠 <strong>DeepSeek-R1</strong> | 671 Billion Parameter Reasoning Expert, Open Source Challenger to OpenAI o1
  </p>
</div>