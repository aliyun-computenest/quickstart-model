<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="计算巢是阿里云开放给企业应用服务商的服务管理平台。服务商能够在计算巢上发布私有化部署服务，为其客户提供云上软件一键部署的能力；同时也支持全托管模式的服务，赋能服务商托管其客户资源。">
  <title>简介 - Aliyun 计算巢 x Demo</title>

  <link rel="shortcut icon" href="../../img/favicon.ico">

  <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.0/build/pure-min.css">
  <link rel="stylesheet" href="../../css/theme.css">
  

  

  
  

  
    <script src="../../search/main.js"></script>
  

  

  <script src="../../js/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>

<body>
  <div class="container">
    <div class="nav">
      <div class="nav-inner">
        <div class="logo">
          <img src="./img/logo-2x.png">
        </div>
        <div class="nav-list">
          <ul>
          
              <li><a href="#_1">简介</a></li>
              
          
          </ul>
        </div>
      </div>
    </div>
    <div class="content theme-github">
      
      <div class="content-inner">        
        
        <h1 id="_1">简介</h1>
<p>我们发布了 gpt-oss-120b 和 gpt-oss-20b——两款性能卓越的开放轻量级语言模型，可在低成本下实现强大的实际应用性能。这些模型在灵活的 Apache 2.0 许可证下提供，与同等规模的开放模型相比，在推理任务中表现更优，展现出强大的工具使用能力，并针对在消费级硬件上高效部署进行了优化。它们通过强化学习与 OpenAI 最先进内部模型（包括 o3 及其他前沿系统）所启发的技术相结合进行训练。</p>
<p>Gpt-oss-120b 模型在核心推理基准测试中与 OpenAI o4-mini 模型几乎持平，同时能在单个 80GB GPU 上高效运行。Gpt-oss-20b 模型在常见基准测试中与 OpenAI o3‑mini 模型取得类似结果，且可在仅配备 16GB 内存的边缘设备上运行，使其成为设备端应用、本地推理或无需昂贵基础设施的快速迭代的理想选择。这两个模型在工具使用、少样本函数调用、CoT推理（如在 Tau-Bench 智能体评估套件中的结果所示）以及 HealthBench 测试中表现强劲（甚至超越了 OpenAI o1 和 GPT‑4o 等专有模型）。</p>
        
      </div>

      <div class="copyrights">© 2009-2022 Aliyun.com 版权所有</div>
    </div>
  </div>
  
  <!--
  MkDocs version      : 1.6.1
  Docs Build Date UTC : 2025-09-17 10:39:36.310232+00:00
  -->
</body>
</html>