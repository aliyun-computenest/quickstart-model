<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="è®¡ç®—å·¢æ˜¯é˜¿é‡Œäº‘å¼€æ”¾ç»™ä¼ä¸šåº”ç”¨æœåŠ¡å•†çš„æœåŠ¡ç®¡ç†å¹³å°ã€‚æœåŠ¡å•†èƒ½å¤Ÿåœ¨è®¡ç®—å·¢ä¸Šå‘å¸ƒç§æœ‰åŒ–éƒ¨ç½²æœåŠ¡ï¼Œä¸ºå…¶å®¢æˆ·æä¾›äº‘ä¸Šè½¯ä»¶ä¸€é”®éƒ¨ç½²çš„èƒ½åŠ›ï¼›åŒæ—¶ä¹Ÿæ”¯æŒå…¨æ‰˜ç®¡æ¨¡å¼çš„æœåŠ¡ï¼Œèµ‹èƒ½æœåŠ¡å•†æ‰˜ç®¡å…¶å®¢æˆ·èµ„æºã€‚">
  <title>Index - Aliyun è®¡ç®—å·¢ x Demo</title>

  <link rel="shortcut icon" href="../../../img/favicon.ico">

  <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.0/build/pure-min.css">
  <link rel="stylesheet" href="../../../css/theme.css">
  

  

  
  

  
    <script src="../../../search/main.js"></script>
  

  

  <script src="../../../js/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>

<body>
  <div class="container">
    <div class="nav">
      <div class="nav-inner">
        <div class="logo">
          <img src="./img/logo-2x.png">
        </div>
        <div class="nav-list">
          <ul>
          
              <li><a href="#_1">ğŸ“‹ æ¨¡å‹æ¦‚è§ˆ</a></li>
              
          
              <li><a href="#comfyui">ğŸš€ ComfyUI åŸç”Ÿå·¥ä½œæµ</a></li>
              
                  <li><a href="#_2">ğŸ“¥ æ­¥éª¤ä¸€ï¼šå·¥ä½œæµæ–‡ä»¶ä¸‹è½½</a></li>
                  
              
                  <li><a href="#_3">ğŸ”— æ­¥éª¤äºŒï¼šæ¨¡å‹æ–‡ä»¶</a></li>
                  
              
          
          </ul>
        </div>
      </div>
    </div>
    <div class="content theme-github">
      
      <div class="content-inner">        
        
        <div style="background: linear-gradient(135deg, #2563eb, #1e40af); padding: 24px; border-radius: 8px; color: white; text-align: center; margin-bottom: 24px;">
  <h1 style="font-size: 2.5em; margin: 0; font-weight: 600;">ğŸµ Wan2.2-S2V éŸ³é¢‘é©±åŠ¨è§†é¢‘ç”Ÿæˆ</h1>
  <p style="font-size: 1.2em; margin: 16px 0 0 0; opacity: 0.9;">ComfyUI åŸç”Ÿå·¥ä½œæµ - å°†é™æ€å›¾ç‰‡ä¸éŸ³é¢‘è½¬åŒ–ä¸ºåŠ¨æ€è§†é¢‘</p>
  <div style="margin-top: 20px;">
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">ğŸ¤ éŸ³é¢‘é©±åŠ¨</span>
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">ğŸ¬ ç”µå½±çº§ç”»è´¨</span>
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">â±ï¸ åˆ†é’Ÿçº§ç”Ÿæˆ</span>
  </div>
</div>

<h2 id="_1">ğŸ“‹ æ¨¡å‹æ¦‚è§ˆ</h2>
<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

æˆ‘ä»¬å¾ˆé«˜å…´åœ°å®£å¸ƒï¼Œå…ˆè¿›çš„éŸ³é¢‘é©±åŠ¨è§†é¢‘ç”Ÿæˆæ¨¡å‹ **Wan2.2-S2V** ç°å·²åŸç”Ÿæ”¯æŒ ComfyUIï¼è¿™ä¸ªå¼ºå¤§çš„ AI æ¨¡å‹å¯ä»¥å°†é™æ€å›¾ç‰‡å’ŒéŸ³é¢‘è¾“å…¥è½¬åŒ–ä¸ºåŠ¨æ€è§†é¢‘å†…å®¹ï¼Œæ”¯æŒå¯¹è¯ã€å”±æ­Œã€è¡¨æ¼”ç­‰å¤šç§åˆ›æ„å†…å®¹éœ€æ±‚ã€‚

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 16px; margin: 16px 0;">
  <div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
    <strong>ğŸµ éŸ³é¢‘é©±åŠ¨è§†é¢‘ç”Ÿæˆ</strong><br>
    <p style="margin: 8px 0 0 0; color: #1e40af; font-size: 14px;">å°†é™æ€å›¾ç‰‡å’ŒéŸ³é¢‘è½¬åŒ–ä¸ºåŒæ­¥è§†é¢‘</p>
  </div>

  <div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
    <strong>ğŸ¬ ç”µå½±çº§ç”»è´¨</strong><br>
    <p style="margin: 8px 0 0 0; color: #065f46; font-size: 14px;">ç”Ÿæˆå…·æœ‰è‡ªç„¶è¡¨æƒ…å’ŒåŠ¨ä½œçš„é«˜è´¨é‡è§†é¢‘</p>
  </div>

  <div style="background: #fef3c7; border-left: 4px solid #d97706; padding: 16px; border-radius: 4px;">
    <strong>â±ï¸ åˆ†é’Ÿçº§ç”Ÿæˆ</strong><br>
    <p style="margin: 8px 0 0 0; color: #9a3412; font-size: 14px;">æ”¯æŒé•¿æ—¶é•¿è§†é¢‘åˆ›ä½œ</p>
  </div>

  <div style="background: #f3e8ff; border-left: 4px solid #7c3aed; padding: 16px; border-radius: 4px;">
    <strong>ğŸ­ å¤šæ ¼å¼æ”¯æŒ</strong><br>
    <p style="margin: 8px 0 0 0; color: #5b21b6; font-size: 14px;">é€‚ç”¨äºå…¨èº«å’ŒåŠèº«è§’è‰²</p>
  </div>
</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ğŸ”— ç›¸å…³èµ„æº</strong><br>
  â€¢ <strong>ä»£ç ä»“åº“</strong>ï¼š<a href="https://github.com/aigc-apps/VideoX-Fun" target="_blank" style="color: #2563eb;">Github</a><br>
  â€¢ <strong>æ¨¡å‹ä»“åº“</strong>ï¼š<a href="https://huggingface.co/Wan-AI/Wan2.2-S2V-14B" target="_blank" style="color: #2563eb;">Hugging Face</a>
</div>

</div>

<h2 id="comfyui">ğŸš€ ComfyUI åŸç”Ÿå·¥ä½œæµ</h2>
<h3 id="_2">ğŸ“¥ æ­¥éª¤ä¸€ï¼šå·¥ä½œæµæ–‡ä»¶ä¸‹è½½</h3>
<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">
ç›´æ¥ä»Comfyuiæ¨¡ç‰ˆæ‰“å¼€

![img.png](img.png)
æˆ–ä¸‹è½½ä»¥ä¸‹å·¥ä½œæµæ–‡ä»¶å¹¶æ‹–å…¥ ComfyUI ä¸­åŠ è½½å·¥ä½œæµã€‚

<div style="text-align: center; margin: 20px 0;">
  <video controls style="width: 100%; max-width: 800px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" src="https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/video/wan/wan2.2_s2v/wan2.2-s2v.mp4"></video>
</div>

<div style="text-align: center; margin: 20px 0;">
  <a href="https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/video_wan2_2_14B_s2v.json" target="_blank" style="display: inline-block; background: linear-gradient(135deg, #2563eb, #1e40af); color: white; padding: 12px 24px; border-radius: 8px; text-decoration: none; font-weight: bold; box-shadow: 0 4px 8px rgba(37, 99, 235, 0.3);">
    ğŸ“„ ä¸‹è½½ JSON å·¥ä½œæµæ–‡ä»¶
  </a>
</div>

### ğŸ“ ç¤ºä¾‹è¾“å…¥æ–‡ä»¶

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 12px 0;">ğŸ–¼ï¸ ç¤ºä¾‹å›¾ç‰‡</h4>
<div style="text-align: center; margin: 12px 0;">
  <img src="https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/video/wan/wan2.2_s2v/input.jpg" alt="ç¤ºä¾‹è¾“å…¥å›¾ç‰‡" style="max-width: 100%; border-radius: 6px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
</div>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
<h4 style="color: #ea580c; margin: 0 0 12px 0;">ğŸµ ç¤ºä¾‹éŸ³é¢‘</h4>
<div style="text-align: center; margin: 12px 0;">
  <a href="https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/video/wan/wan2.2_s2v/input_audio.MP3" target="_blank" style="display: inline-block; background: #ea580c; color: white; padding: 8px 16px; border-radius: 6px; text-decoration: none; font-weight: bold;">
    ğŸ§ ä¸‹è½½è¾“å…¥éŸ³é¢‘
  </a>
</div>
</div>

</div>

</div>

<h3 id="_3">ğŸ”— æ­¥éª¤äºŒï¼šæ¨¡å‹æ–‡ä»¶</h3>
<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">


#### ğŸ“‚ æ¨¡å‹æ–‡ä»¶ç»“æ„

<div style="background: #1e293b; border-radius: 6px; padding: 16px; margin: 16px 0;">
<pre style="margin: 0; color: #e2e8f0; font-family: 'Courier New', monospace; font-size: 14px;"><code>ComfyUI/
â”œâ”€â”€â”€ğŸ“‚ models/
â”‚   â”œâ”€â”€â”€ğŸ“‚ diffusion_models/
â”‚   â”‚   â”œâ”€â”€â”€â”€ wan2.2_s2v_14B_fp8_scaled.safetensors
â”‚   â”‚   â””â”€â”€â”€â”€ wan2.2_s2v_14B_bf16.safetensors
â”‚   â”œâ”€â”€â”€ğŸ“‚ text_encoders/
â”‚   â”‚   â””â”€â”€â”€â”€ umt5_xxl_fp8_e4m3fn_scaled.safetensors 
â”‚   â”œâ”€â”€â”€ğŸ“‚ audio_encoders/ # å¦‚æœè¿™ä¸ªæ–‡ä»¶å¤¹ä¸å­˜åœ¨è¯·æ‰‹åŠ¨åˆ›å»º
â”‚   â”‚   â””â”€â”€â”€â”€ wav2vec2_large_english_fp16.safetensors 
â”‚   â””â”€â”€â”€ğŸ“‚ vae/
â”‚       â””â”€â”€â”€â”€ wan_2.1_vae.safetensors</code></pre>
</div>

### ğŸ”§ æ­¥éª¤ä¸‰ï¼šå·¥ä½œæµé…ç½®è¯´æ˜

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<div style="text-align: center; margin: 20px 0;">
  <img src="https://mintcdn.com/dripart/ht3vzHrjy1qaRsl9/images/tutorial/video/wan/wan_2.2_14b_s2v.jpg?fit=max&auto=format&n=ht3vzHrjy1qaRsl9&q=85&s=295f87179e12d937cbfbcc3e21d474c0" alt="å·¥ä½œæµè¯´æ˜" style="width: 100%; max-width: 1200px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
</div>

#### ğŸ¯ æ¨¡å‹é€‰æ‹©è¯´æ˜

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
<h4 style="color: #2563eb; margin: 0 0 8px 0;">ğŸ’¾ FP8 Scaled æ¨¡å‹</h4>
<p style="margin: 0 0 8px 0; color: #1e40af; font-size: 14px;"><strong>wan2.2_s2v_14B_fp8_scaled.safetensors</strong></p>
<div style="background: #dcfce7; color: #059669; padding: 4px 12px; border-radius: 12px; font-size: 12px; display: inline-block;">âœ… æ¨èä½¿ç”¨</div>
<p style="margin: 8px 0 0 0; color: #64748b; font-size: 13px;">éœ€è¦æ›´å°‘çš„æ˜¾å­˜ï¼Œé€‚åˆå¤§å¤šæ•°ç”¨æˆ·</p>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
<h4 style="color: #ea580c; margin: 0 0 8px 0;">ğŸ¯ BF16 æ¨¡å‹</h4>
<p style="margin: 0 0 8px 0; color: #9a3412; font-size: 14px;"><strong>wan2.2_s2v_14B_bf16.safetensors</strong></p>
<div style="background: #fed7aa; color: #ea580c; padding: 4px 12px; border-radius: 12px; font-size: 12px; display: inline-block;">âš¡ é«˜è´¨é‡</div>
<p style="margin: 8px 0 0 0; color: #64748b; font-size: 13px;">å‡å°‘è´¨é‡æŸå¤±ï¼Œéœ€è¦æ›´å¤šæ˜¾å­˜</p>
</div>

</div>

#### âš¡ Lightning LoRA è¯´æ˜

<div style="background: #fef3c7; border-left: 4px solid #d97706; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>âš ï¸ Lightning LoRA æ³¨æ„äº‹é¡¹</strong><br>
  â€¢ æµ‹è¯•äº†æ‰€æœ‰ wan2.2 lightning LoRAsï¼Œç”±äºè¿™å¹¶ä¸æ˜¯ä¸“é—¨ä¸º Wan2.2 S2V è®­ç»ƒçš„ LoRA<br>
  â€¢ å¾ˆå¤šé”®å€¼ä¸åŒ¹é…ï¼Œä½†èƒ½å¤§å¹…å‡å°‘ç”Ÿæˆæ—¶é—´<br>
  â€¢ ä½¿ç”¨å®ƒä¼šå¯¼è‡´æå¤§çš„åŠ¨æ€å’Œè´¨é‡æŸå¤±<br>
  â€¢ å¦‚æœè¾“å‡ºè´¨é‡å¤ªå·®ï¼Œå¯ä»¥å°è¯•åŸå§‹çš„ 20 æ­¥å·¥ä½œæµ
</div>

</div>

## ğŸ“‹ è¯¦ç»†æ“ä½œæ­¥éª¤

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

### ğŸ”§ æ­¥éª¤ 1ï¼šæ¨¡å‹åŠ è½½é…ç½®

<div style="overflow-x: auto; margin: 16px 0;">
<table style="width: 100%; border-collapse: collapse; background: white; border-radius: 6px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
  <thead style="background: #f8fafc;">
    <tr>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">èŠ‚ç‚¹åç§°</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">æ¨¡å‹æ–‡ä»¶</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">è¯´æ˜</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Load Diffusion Model</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-family: monospace; font-size: 12px;">wan2.2_s2v_14B_fp8_scaled.safetensors</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">ä¸»è¦æ‰©æ•£æ¨¡å‹ï¼ˆæ¨èï¼‰</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Load CLIP</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-family: monospace; font-size: 12px;">umt5_xxl_fp8_e4m3fn_scaled.safetensors</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">æ–‡æœ¬ç¼–ç å™¨</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Load VAE</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-family: monospace; font-size: 12px;">wan_2.1_vae.safetensors</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">å˜åˆ†è‡ªç¼–ç å™¨</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Audio</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-family: monospace; font-size: 12px;">wav2vec2_large_english_fp16.safetensors</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">éŸ³é¢‘ç¼–ç å™¨</td>
    </tr>
    <tr>
      <td style="padding: 12px; font-weight: 500;">LoraLoaderModelOnly</td>
      <td style="padding: 12px; font-family: monospace; font-size: 12px;">wan2.2_t2v_lightx2v_4steps_lora_v1.1_high_noise.safetensors</td>
      <td style="padding: 12px;">Lightning LoRAï¼ˆå¯é€‰ï¼‰</td>
    </tr>
  </tbody>
</table>
</div>

### ğŸ“ æ­¥éª¤ 2ï¼šè¾“å…¥æ–‡ä»¶é…ç½®

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">ğŸµ LoadAudio</h4>
<p style="margin: 0 0 8px 0; color: #065f46;">ä¸Šä¼ æä¾›çš„éŸ³é¢‘æ–‡ä»¶ï¼Œæˆ–è€…ä½ è‡ªå·±çš„éŸ³é¢‘</p>
<div style="background: #dcfce7; color: #059669; padding: 4px 12px; border-radius: 12px; font-size: 12px; display: inline-block;">æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼</div>
</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
<h4 style="color: #2563eb; margin: 0 0 8px 0;">ğŸ–¼ï¸ Load Image</h4>
<p style="margin: 0 0 8px 0; color: #1e40af;">ä¸Šä¼ å‚è€ƒå›¾ç‰‡</p>
<div style="background: #dbeafe; color: #2563eb; padding: 4px 12px; border-radius: 12px; font-size: 12px; display: inline-block;">æ”¯æŒå…¨èº«å’ŒåŠèº«è§’è‰²</div>
</div>

</div>

### âš™ï¸ æ­¥éª¤ 3ï¼šå‚æ•°é…ç½®

<div style="overflow-x: auto; margin: 16px 0;">
<table style="width: 100%; border-collapse: collapse; background: white; border-radius: 6px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
  <thead style="background: #f8fafc;">
    <tr>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">å‚æ•°åç§°</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">æ¨èå€¼</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">è¯´æ˜</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Batch sizes</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">æ ¹æ®æ‰©å±•èŠ‚ç‚¹æ•°é‡è®¾ç½®</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">æ€»é‡‡æ ·æ¬¡æ•°</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Chunk Length</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">77</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">ä¿æŒé»˜è®¤å€¼</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Steps (Lightning LoRA)</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">4</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">ä½¿ç”¨ Lightning LoRA æ—¶</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Steps (æ ‡å‡†)</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">20</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">ä¸ä½¿ç”¨ Lightning LoRA æ—¶</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">CFG (Lightning LoRA)</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">1.0</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">ä½¿ç”¨ Lightning LoRA æ—¶</td>
    </tr>
    <tr>
      <td style="padding: 12px; font-weight: 500;">CFG (æ ‡å‡†)</td>
      <td style="padding: 12px;">6.0</td>
      <td style="padding: 12px;">ä¸ä½¿ç”¨ Lightning LoRA æ—¶</td>
    </tr>
  </tbody>
</table>
</div>

### ğŸ¬ æ­¥éª¤ 4ï¼šè§†é¢‘æ‰©å±•é…ç½®

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ğŸ“Š Video S2V Extend è®¡ç®—å…¬å¼</strong><br>
  â€¢ æ¯ä¸ªæ‰©å±•èŠ‚ç‚¹ç”Ÿæˆ 77 å¸§<br>
  â€¢ æ¨¡å‹å¸§ç‡ä¸º 16fps<br>
  â€¢ æ¯ä¸ªæ‰©å±• = 77 Ã· 16 = 4.8125 ç§’<br>
  â€¢ æ‰€éœ€æ‰©å±•æ•°é‡ = éŸ³é¢‘æ—¶é•¿(ç§’) Ã— 16 Ã· 77ï¼ˆå‘ä¸Šå–æ•´ï¼‰
</div>

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ğŸ’¡ ç¤ºä¾‹è®¡ç®—</strong><br>
  å¦‚æœè¾“å…¥éŸ³é¢‘ä¸º 14 ç§’ï¼š<br>
  â€¢ æ€»å¸§æ•° = 14 Ã— 16 = 224 å¸§<br>
  â€¢ æ‰©å±•æ•°é‡ = 224 Ã· 77 = 2.9 â†’ å‘ä¸Šå–æ•´ä¸º 3<br>
  â€¢ éœ€è¦ 3 ä¸ª Video S2V Extend èŠ‚ç‚¹
</div>

### ğŸš€ æ­¥éª¤ 5ï¼šæ‰§è¡Œå·¥ä½œæµ

<div style="text-align: center; margin: 20px 0;">
  <div style="background: linear-gradient(135deg, #059669, #047857); color: white; padding: 16px 32px; border-radius: 8px; display: inline-block; box-shadow: 0 4px 8px rgba(5, 150, 105, 0.3);">
    <strong>âŒ¨ï¸ ä½¿ç”¨ Ctrl+Enter æˆ–ç‚¹å‡»è¿è¡ŒæŒ‰é’®æ¥æ‰§è¡Œå·¥ä½œæµ</strong>
  </div>
</div>

</div>

## APIè°ƒç”¨
<details style="border: 2px solid #2563eb; border-radius: 12px; padding: 20px; margin: 20px 0; background: linear-gradient(145deg, #f8fafc, #eff6ff); box-shadow: 0 8px 16px rgba(37, 99, 235, 0.15);">
<summary style="font-weight: bold; font-size: 18px; color: white; cursor: pointer; padding: 16px; background: linear-gradient(135deg, #2563eb, #1e40af); border-radius: 8px; margin: -20px -20px 20px -20px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); transition: all 0.3s ease; display: flex; align-items: center; box-shadow: 0 4px 8px rgba(37, 99, 235, 0.3);">
ğŸ“‹ ç‚¹å‡»å±•å¼€ComfyUI APIè°ƒç”¨Pythonä»£ç 
</summary>


<pre><code class="language-python">
import requests
import json
import uuid
import time
import random
import os

# Configuration Parameters - Wan2.2 Sound-to-Video Specific
COMFYUI_SERVER = &quot;127.0.0.1:8188&quot;  # Local server
COMFYUI_TOKEN = &quot;&quot;  # Usually no token needed for local

# Model Configuration
UNET_MODEL = &quot;wan2.2_s2v_14B_fp8_scaled.safetensors&quot;
CLIP_MODEL = &quot;umt5_xxl_fp8_e4m3fn_scaled.safetensors&quot;
VAE_MODEL = &quot;wan_2.1_vae.safetensors&quot;
AUDIO_ENCODER_MODEL = &quot;wav2vec2_large_english_fp16.safetensors&quot;
LORA_MODEL = &quot;wan2.2_t2v_lightx2v_4steps_lora_v1.1_high_noise.safetensors&quot;

# Default Parameters
DEFAULT_POSITIVE_PROMPT = &quot;The man is playing the guitar. He looks down at his hands playing the guitar and sings affectionately and gently.&quot;
DEFAULT_NEGATIVE_PROMPT = &quot;è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°&quot;
DEFAULT_REF_IMAGE = &quot;Zoomable image (6).jpg&quot;
DEFAULT_AUDIO = &quot;music.MP3&quot;

class ComfyUIWan22SoundToVideoClient:
    def __init__(self, server=COMFYUI_SERVER, token=COMFYUI_TOKEN):
        self.base_url = f&quot;http://{server}&quot;
        self.token = token
        self.client_id = str(uuid.uuid4())
        self.headers = {&quot;Content-Type&quot;: &quot;application/json&quot;}
        if token:
            self.headers[&quot;Authorization&quot;] = f&quot;Bearer {token}&quot;

    def upload_image(self, image_path):
        &quot;&quot;&quot;Upload image to ComfyUI server&quot;&quot;&quot;
        try:
            with open(image_path, 'rb') as f:
                files = {'image': f}
                response = requests.post(f&quot;{self.base_url}/upload/image&quot;, files=files)
                if response.status_code == 200:
                    result = response.json()
                    return result.get('name', os.path.basename(image_path))
                else:
                    raise Exception(f&quot;Failed to upload image: {response.text}&quot;)
        except Exception as e:
            print(f&quot;Image upload error: {e}&quot;)
            return None

    def upload_audio(self, audio_path):
        &quot;&quot;&quot;Upload audio to ComfyUI server&quot;&quot;&quot;
        try:
            with open(audio_path, 'rb') as f:
                files = {'audio': f}
                response = requests.post(f&quot;{self.base_url}/upload/audio&quot;, files=files)
                if response.status_code == 200:
                    result = response.json()
                    return result.get('name', os.path.basename(audio_path))
                else:
                    raise Exception(f&quot;Failed to upload audio: {response.text}&quot;)
        except Exception as e:
            print(f&quot;Audio upload error: {e}&quot;)
            return None

    def generate_sound_to_video(self, positive_prompt, negative_prompt=None,
                               ref_image_path=None, ref_image_name=None,
                               audio_path=None, audio_name=None,
                               width=640, height=640, chunk_length=77,
                               steps=4, cfg=1, fps=16, seed=20,
                               batch_index=3, shift=8.0, lora_strength=1.0,
                               extend_chunks=2):
        &quot;&quot;&quot;Generate Sound-to-Video using Wan2.2 based on original JSON workflow&quot;&quot;&quot;
        print(&quot;Starting Wan2.2 Sound-to-Video generation...&quot;)

        # Use default negative prompt if not provided
        if negative_prompt is None:
            negative_prompt = DEFAULT_NEGATIVE_PROMPT

        # Handle reference image
        if ref_image_path and not ref_image_name:
            ref_image_name = self.upload_image(ref_image_path)
            if not ref_image_name:
                raise Exception(&quot;Failed to upload reference image&quot;)
        elif not ref_image_name:
            ref_image_name = DEFAULT_REF_IMAGE

        # Handle audio file
        if audio_path and not audio_name:
            audio_name = self.upload_audio(audio_path)
            if not audio_name:
                raise Exception(&quot;Failed to upload audio file&quot;)
        elif not audio_name:
            audio_name = DEFAULT_AUDIO

        # Calculate total length based on chunks
        total_length = chunk_length * (extend_chunks + 1)

        # Workflow based on your provided JSON
        workflow = {
            &quot;3&quot;: {
                &quot;inputs&quot;: {
                    &quot;seed&quot;: seed,
                    &quot;steps&quot;: [&quot;103&quot;, 0],
                    &quot;cfg&quot;: [&quot;105&quot;, 0],
                    &quot;sampler_name&quot;: &quot;uni_pc&quot;,
                    &quot;scheduler&quot;: &quot;simple&quot;,
                    &quot;denoise&quot;: 1,
                    &quot;model&quot;: [&quot;54&quot;, 0],
                    &quot;positive&quot;: [&quot;93&quot;, 0],
                    &quot;negative&quot;: [&quot;93&quot;, 1],
                    &quot;latent_image&quot;: [&quot;93&quot;, 2]
                },
                &quot;class_type&quot;: &quot;KSampler&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;K Sampler (Initial)&quot;}
            },
            &quot;6&quot;: {
                &quot;inputs&quot;: {
                    &quot;text&quot;: positive_prompt,
                    &quot;clip&quot;: [&quot;38&quot;, 0]
                },
                &quot;class_type&quot;: &quot;CLIPTextEncode&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;CLIP Text Encode (Positive Prompt)&quot;}
            },
            &quot;7&quot;: {
                &quot;inputs&quot;: {
                    &quot;text&quot;: negative_prompt,
                    &quot;clip&quot;: [&quot;38&quot;, 0]
                },
                &quot;class_type&quot;: &quot;CLIPTextEncode&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;CLIP Text Encode (Negative Prompt)&quot;}
            },
            &quot;37&quot;: {
                &quot;inputs&quot;: {
                    &quot;unet_name&quot;: UNET_MODEL,
                    &quot;weight_dtype&quot;: &quot;default&quot;
                },
                &quot;class_type&quot;: &quot;UNETLoader&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;UNet Loader&quot;}
            },
            &quot;38&quot;: {
                &quot;inputs&quot;: {
                    &quot;clip_name&quot;: CLIP_MODEL,
                    &quot;type&quot;: &quot;wan&quot;,
                    &quot;device&quot;: &quot;default&quot;
                },
                &quot;class_type&quot;: &quot;CLIPLoader&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;CLIP Loader&quot;}
            },
            &quot;39&quot;: {
                &quot;inputs&quot;: {
                    &quot;vae_name&quot;: VAE_MODEL
                },
                &quot;class_type&quot;: &quot;VAELoader&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;VAE Loader&quot;}
            },
            &quot;52&quot;: {
                &quot;inputs&quot;: {
                    &quot;image&quot;: ref_image_name
                },
                &quot;class_type&quot;: &quot;LoadImage&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Load Reference Image&quot;}
            },
            &quot;54&quot;: {
                &quot;inputs&quot;: {
                    &quot;shift&quot;: shift,
                    &quot;model&quot;: [&quot;107&quot;, 0]
                },
                &quot;class_type&quot;: &quot;ModelSamplingSD3&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Model Sampling SD3&quot;}
            },
            &quot;56&quot;: {
                &quot;inputs&quot;: {
                    &quot;audio_encoder&quot;: [&quot;57&quot;, 0],
                    &quot;audio&quot;: [&quot;58&quot;, 0]
                },
                &quot;class_type&quot;: &quot;AudioEncoderEncode&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Audio Encoder Encode&quot;}
            },
            &quot;57&quot;: {
                &quot;inputs&quot;: {
                    &quot;audio_encoder_name&quot;: AUDIO_ENCODER_MODEL
                },
                &quot;class_type&quot;: &quot;AudioEncoderLoader&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Audio Encoder Loader&quot;}
            },
            &quot;58&quot;: {
                &quot;inputs&quot;: {
                    &quot;audio&quot;: audio_name,
                    &quot;audioUI&quot;: &quot;&quot;
                },
                &quot;class_type&quot;: &quot;LoadAudio&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Load Audio&quot;}
            },
            &quot;80&quot;: {
                &quot;inputs&quot;: {
                    &quot;samples&quot;: [&quot;95&quot;, 0],
                    &quot;vae&quot;: [&quot;39&quot;, 0]
                },
                &quot;class_type&quot;: &quot;VAEDecode&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;VAE Decode&quot;}
            },
            &quot;82&quot;: {
                &quot;inputs&quot;: {
                    &quot;fps&quot;: fps,
                    &quot;images&quot;: [&quot;96&quot;, 0],
                    &quot;audio&quot;: [&quot;58&quot;, 0]
                },
                &quot;class_type&quot;: &quot;CreateVideo&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Create Video&quot;}
            },
            &quot;93&quot;: {
                &quot;inputs&quot;: {
                    &quot;width&quot;: width,
                    &quot;height&quot;: height,
                    &quot;length&quot;: [&quot;104&quot;, 0],
                    &quot;batch_size&quot;: 1,
                    &quot;positive&quot;: [&quot;6&quot;, 0],
                    &quot;negative&quot;: [&quot;7&quot;, 0],
                    &quot;vae&quot;: [&quot;39&quot;, 0],
                    &quot;audio_encoder_output&quot;: [&quot;56&quot;, 0],
                    &quot;ref_image&quot;: [&quot;52&quot;, 0]
                },
                &quot;class_type&quot;: &quot;WanSoundImageToVideo&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Wan Sound Image To Video&quot;}
            },
            &quot;94&quot;: {
                &quot;inputs&quot;: {
                    &quot;dim&quot;: &quot;t&quot;,
                    &quot;index&quot;: 0,
                    &quot;amount&quot;: 1,
                    &quot;samples&quot;: [&quot;85:78&quot;, 0]
                },
                &quot;class_type&quot;: &quot;LatentCut&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Latent Cut&quot;}
            },
            &quot;95&quot;: {
                &quot;inputs&quot;: {
                    &quot;dim&quot;: &quot;t&quot;,
                    &quot;samples1&quot;: [&quot;94&quot;, 0],
                    &quot;samples2&quot;: [&quot;85:78&quot;, 0]
                },
                &quot;class_type&quot;: &quot;LatentConcat&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Latent Concat&quot;}
            },
            &quot;96&quot;: {
                &quot;inputs&quot;: {
                    &quot;batch_index&quot;: [&quot;100&quot;, 0],
                    &quot;length&quot;: 4096,
                    &quot;image&quot;: [&quot;80&quot;, 0]
                },
                &quot;class_type&quot;: &quot;ImageFromBatch&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Image From Batch&quot;}
            },
            &quot;100&quot;: {
                &quot;inputs&quot;: {
                    &quot;value&quot;: batch_index
                },
                &quot;class_type&quot;: &quot;PrimitiveInt&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Batch Index&quot;}
            },
            &quot;103&quot;: {
                &quot;inputs&quot;: {
                    &quot;value&quot;: steps
                },
                &quot;class_type&quot;: &quot;PrimitiveInt&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Steps&quot;}
            },
            &quot;104&quot;: {
                &quot;inputs&quot;: {
                    &quot;value&quot;: chunk_length
                },
                &quot;class_type&quot;: &quot;PrimitiveInt&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Chunk Length&quot;}
            },
            &quot;105&quot;: {
                &quot;inputs&quot;: {
                    &quot;value&quot;: cfg
                },
                &quot;class_type&quot;: &quot;PrimitiveFloat&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;CFG&quot;}
            },
            &quot;107&quot;: {
                &quot;inputs&quot;: {
                    &quot;lora_name&quot;: LORA_MODEL,
                    &quot;strength_model&quot;: lora_strength,
                    &quot;model&quot;: [&quot;37&quot;, 0]
                },
                &quot;class_type&quot;: &quot;LoraLoaderModelOnly&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;LoRA Loader&quot;}
            },
            &quot;113&quot;: {
                &quot;inputs&quot;: {
                    &quot;filename_prefix&quot;: &quot;wan22_sound_to_video/video&quot;,
                    &quot;format&quot;: &quot;auto&quot;,
                    &quot;codec&quot;: &quot;auto&quot;,
                    &quot;video&quot;: [&quot;82&quot;, 0]
                },
                &quot;class_type&quot;: &quot;SaveVideo&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Save Video&quot;}
            }
        }

        # Add extension chunks if needed
        if extend_chunks &gt;= 1:
            workflow[&quot;79:78&quot;] = {
                &quot;inputs&quot;: {
                    &quot;dim&quot;: &quot;t&quot;,
                    &quot;samples1&quot;: [&quot;3&quot;, 0],
                    &quot;samples2&quot;: [&quot;79:77&quot;, 0]
                },
                &quot;class_type&quot;: &quot;LatentConcat&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Latent Concat (Extend 1)&quot;}
            }
            workflow[&quot;79:77&quot;] = {
                &quot;inputs&quot;: {
                    &quot;seed&quot;: 1,
                    &quot;steps&quot;: 10,
                    &quot;cfg&quot;: [&quot;103&quot;, 0],
                    &quot;sampler_name&quot;: &quot;uni_pc&quot;,
                    &quot;scheduler&quot;: &quot;simple&quot;,
                    &quot;denoise&quot;: 1,
                    &quot;model&quot;: [&quot;54&quot;, 0],
                    &quot;positive&quot;: [&quot;79:76&quot;, 0],
                    &quot;negative&quot;: [&quot;79:76&quot;, 1],
                    &quot;latent_image&quot;: [&quot;79:76&quot;, 2]
                },
                &quot;class_type&quot;: &quot;KSampler&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;K Sampler (Extend 1)&quot;}
            }
            workflow[&quot;79:76&quot;] = {
                &quot;inputs&quot;: {
                    &quot;length&quot;: [&quot;105&quot;, 0],
                    &quot;positive&quot;: [&quot;6&quot;, 0],
                    &quot;negative&quot;: [&quot;7&quot;, 0],
                    &quot;vae&quot;: [&quot;39&quot;, 0],
                    &quot;video_latent&quot;: [&quot;3&quot;, 0],
                    &quot;audio_encoder_output&quot;: [&quot;56&quot;, 0],
                    &quot;ref_image&quot;: [&quot;52&quot;, 0]
                },
                &quot;class_type&quot;: &quot;WanSoundImageToVideoExtend&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Wan Sound Image To Video Extend 1&quot;}
            }

        if extend_chunks &gt;= 2:
            workflow[&quot;85:78&quot;] = {
                &quot;inputs&quot;: {
                    &quot;dim&quot;: &quot;t&quot;,
                    &quot;samples1&quot;: [&quot;79:78&quot;, 0],
                    &quot;samples2&quot;: [&quot;85:77&quot;, 0]
                },
                &quot;class_type&quot;: &quot;LatentConcat&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Latent Concat (Extend 2)&quot;}
            }
            workflow[&quot;85:77&quot;] = {
                &quot;inputs&quot;: {
                    &quot;seed&quot;: 250,
                    &quot;steps&quot;: 10,
                    &quot;cfg&quot;: [&quot;103&quot;, 0],
                    &quot;sampler_name&quot;: &quot;uni_pc&quot;,
                    &quot;scheduler&quot;: &quot;simple&quot;,
                    &quot;denoise&quot;: 1,
                    &quot;model&quot;: [&quot;54&quot;, 0],
                    &quot;positive&quot;: [&quot;85:76&quot;, 0],
                    &quot;negative&quot;: [&quot;85:76&quot;, 1],
                    &quot;latent_image&quot;: [&quot;85:76&quot;, 2]
                },
                &quot;class_type&quot;: &quot;KSampler&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;K Sampler (Extend 2)&quot;}
            }
            workflow[&quot;85:76&quot;] = {
                &quot;inputs&quot;: {
                    &quot;length&quot;: [&quot;105&quot;, 0],
                    &quot;positive&quot;: [&quot;6&quot;, 0],
                    &quot;negative&quot;: [&quot;7&quot;, 0],
                    &quot;vae&quot;: [&quot;39&quot;, 0],
                    &quot;video_latent&quot;: [&quot;79:78&quot;, 0],
                    &quot;audio_encoder_output&quot;: [&quot;56&quot;, 0],
                    &quot;ref_image&quot;: [&quot;52&quot;, 0]
                },
                &quot;class_type&quot;: &quot;WanSoundImageToVideoExtend&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Wan Sound Image To Video Extend 2&quot;}
            }

        print(&quot;Submitting Wan2.2 Sound-to-Video generation workflow...&quot;)
        print(f&quot;Positive Prompt: {positive_prompt}&quot;)
        print(f&quot;Reference Image: {ref_image_name}&quot;)
        print(f&quot;Audio File: {audio_name}&quot;)
        print(f&quot;Video Dimensions: {width}x{height}&quot;)
        print(f&quot;Chunk Length: {chunk_length} frames&quot;)
        print(f&quot;Total Length: {total_length} frames&quot;)
        print(f&quot;FPS: {fps}&quot;)
        print(f&quot;Steps: {steps}&quot;)
        print(f&quot;CFG: {cfg}&quot;)
        print(f&quot;Seed: {seed}&quot;)
        print(f&quot;Extension Chunks: {extend_chunks}&quot;)

        response = requests.post(
            f&quot;{self.base_url}/prompt&quot;, 
            headers=self.headers, 
            json={&quot;prompt&quot;: workflow, &quot;client_id&quot;: self.client_id}
        )

        print(f&quot;API Response: {response.text}&quot;)

        if response.status_code != 200:
            raise Exception(f&quot;API request failed with status code: {response.status_code}&quot;)

        result = response.json()
        if &quot;error&quot; in result:
            raise Exception(f&quot;Workflow error: {result['error']}&quot;)
        if &quot;prompt_id&quot; not in result:
            raise Exception(f&quot;No prompt_id in response: {result}&quot;)

        return result[&quot;prompt_id&quot;], seed

    def get_status(self, task_id):
        &quot;&quot;&quot;Get task status&quot;&quot;&quot;
        try:
            # Check queue status
            queue_data = requests.get(f&quot;{self.base_url}/queue&quot;, headers=self.headers).json()

            # Check if in running queue
            if any(item[1] == task_id for item in queue_data.get(&quot;queue_running&quot;, [])):
                return &quot;processing&quot;

            # Check if in pending queue
            if any(item[1] == task_id for item in queue_data.get(&quot;queue_pending&quot;, [])):
                return &quot;pending&quot;

            # Check history
            history_response = requests.get(f&quot;{self.base_url}/history/{task_id}&quot;, headers=self.headers)
            if history_response.status_code == 200:
                history = history_response.json()
                if task_id in history:
                    return &quot;completed&quot;

            return &quot;processing&quot;
        except Exception as e:
            print(f&quot;Status check error: {e}&quot;)
            return &quot;processing&quot;

    def download_video(self, task_id, output_dir=&quot;outputs&quot;):
        &quot;&quot;&quot;Download generated video files&quot;&quot;&quot;
        try:
            # Ensure output directory exists
            os.makedirs(output_dir, exist_ok=True)

            response = requests.get(f&quot;{self.base_url}/history/{task_id}&quot;, headers=self.headers)
            history = response.json()

            if task_id in history:
                outputs = history[task_id]['outputs']
                downloaded_files = []

                for node_id, output in outputs.items():
                    # Check for video files
                    if 'videos' in output:
                        for video_info in output['videos']:
                            filename = video_info['filename']
                            # Download video
                            video_response = requests.get(
                                f&quot;{self.base_url}/view?filename={filename}&quot;, 
                                headers=self.headers
                            )

                            if video_response.status_code == 200:
                                output_path = os.path.join(output_dir, filename)
                                with open(output_path, &quot;wb&quot;) as f:
                                    f.write(video_response.content)
                                downloaded_files.append(output_path)
                                print(f&quot;Video saved: {output_path}&quot;)

                    # Check for preview images
                    if 'images' in output:
                        for img_info in output['images']:
                            filename = img_info['filename']
                            # Download preview image
                            img_response = requests.get(
                                f&quot;{self.base_url}/view?filename={filename}&quot;, 
                                headers=self.headers
                            )

                            if img_response.status_code == 200:
                                output_path = os.path.join(output_dir, filename)
                                with open(output_path, &quot;wb&quot;) as f:
                                    f.write(img_response.content)
                                downloaded_files.append(output_path)
                                print(f&quot;Preview image saved: {output_path}&quot;)

                return downloaded_files

        except Exception as e:
            print(f&quot;Download error: {e}&quot;)

        return []

    def generate_batch(self, configs, **kwargs):
        &quot;&quot;&quot;Batch generate sound-to-video with different configurations&quot;&quot;&quot;
        results = []

        for i, config in enumerate(configs):
            print(f&quot;\nStarting Sound-to-Video generation task {i+1}/{len(configs)}...&quot;)

            try:
                task_id, seed = self.generate_sound_to_video(**config, **kwargs)

                # Wait for completion
                while True:
                    status = self.get_status(task_id)
                    print(f&quot;Task {i+1} status: {status}&quot;)

                    if status == &quot;completed&quot;:
                        files = self.download_video(task_id)
                        results.append({
                            'task_id': task_id,
                            'seed': seed,
                            'files': files,
                            'config': config
                        })
                        break
                    elif status == &quot;failed&quot;:
                        print(f&quot;Task {i+1} failed&quot;)
                        break

                    time.sleep(20)  # Sound-to-video generation takes longer

            except Exception as e:
                print(f&quot;Task {i+1} error: {e}&quot;)

        return results

    def generate_with_length_presets(self, positive_prompt, audio_path, ref_image_path, 
                                   length_preset=&quot;medium&quot;):
        &quot;&quot;&quot;Generate with predefined length settings&quot;&quot;&quot;
        length_presets = {
            &quot;short&quot;: {&quot;chunk_length&quot;: 49, &quot;extend_chunks&quot;: 1},
            &quot;medium&quot;: {&quot;chunk_length&quot;: 77, &quot;extend_chunks&quot;: 2},
            &quot;long&quot;: {&quot;chunk_length&quot;: 97, &quot;extend_chunks&quot;: 3},
            &quot;extra_long&quot;: {&quot;chunk_length&quot;: 121, &quot;extend_chunks&quot;: 4}
        }

        settings = length_presets.get(length_preset, length_presets[&quot;medium&quot;])
        return self.generate_sound_to_video(
            positive_prompt=positive_prompt,
            audio_path=audio_path,
            ref_image_path=ref_image_path,
            **settings
        )

def main():
    &quot;&quot;&quot;Main function - Execute Wan2.2 Sound-to-Video generation&quot;&quot;&quot;
    client = ComfyUIWan22SoundToVideoClient()

    try:
        print(&quot;Wan2.2 Sound-to-Video generation client started...&quot;)

        # Single video generation example
        print(&quot;\n=== Single Sound-to-Video Generation ===&quot;)

        # You can provide local file paths or use existing file names
        ref_image_path = None  # Set to your image path, e.g., &quot;reference.jpg&quot;
        audio_path = None  # Set to your audio path, e.g., &quot;music.mp3&quot;

        task_id, seed = client.generate_sound_to_video(
            positive_prompt=DEFAULT_POSITIVE_PROMPT,
            negative_prompt=DEFAULT_NEGATIVE_PROMPT,
            ref_image_path=ref_image_path,
            ref_image_name=DEFAULT_REF_IMAGE,
            audio_path=audio_path,
            audio_name=DEFAULT_AUDIO,
            width=640,
            height=640,
            chunk_length=77,
            steps=4,
            cfg=1,
            fps=16,
            seed=20,
            extend_chunks=2
        )

        print(f&quot;Task ID: {task_id}&quot;)
        print(f&quot;Seed: {seed}&quot;)

        # Wait for task completion (sound-to-video generation takes longer)
        while True:
            status = client.get_status(task_id)
            print(f&quot;Current status: {status}&quot;)

            if status == &quot;completed&quot;:
                print(&quot;Sound-to-Video generation completed!&quot;)
                break
            elif status == &quot;failed&quot;:
                print(&quot;Generation failed!&quot;)
                return

            time.sleep(20)

        # Download video files
        downloaded_files = client.download_video(task_id)
        if downloaded_files:
            print(f&quot;Successfully downloaded {len(downloaded_files)} files!&quot;)
            for file in downloaded_files:
                print(f&quot;File path: {file}&quot;)
        else:
            print(&quot;Download failed&quot;)

        # Length preset example
        print(&quot;\n=== Length Preset Example ===&quot;)
        # Uncomment to test different length presets
        # if ref_image_path and audio_path:
        #     for preset in [&quot;short&quot;, &quot;medium&quot;, &quot;long&quot;]:
        #         print(f&quot;Generating with {preset} length...&quot;)
        #         task_id, seed = client.generate_with_length_presets(
        #             DEFAULT_POSITIVE_PROMPT, audio_path, ref_image_path, preset
        #         )
        #         # Wait and download logic here...

        # Batch generation example
        print(&quot;\n=== Batch Generation Example ===&quot;)
        batch_configs = [
            {
                'positive_prompt': &quot;A musician playing piano in a concert hall&quot;,
                'ref_image_name': DEFAULT_REF_IMAGE,
                'audio_name': DEFAULT_AUDIO,
                'chunk_length': 49,
                'extend_chunks': 1
            },
            {
                'positive_prompt': &quot;A dancer performing to classical music&quot;,
                'ref_image_name': DEFAULT_REF_IMAGE,
                'audio_name': DEFAULT_AUDIO,
                'chunk_length': 77,
                'extend_chunks': 2
            }
        ]

        # Uncomment to run batch generation
        # batch_results = client.generate_batch(batch_configs, fps=16, steps=4)
        # print(f&quot;Batch generation completed, generated {len(batch_results)} videos&quot;)

    except Exception as e:
        print(f&quot;Error: {e}&quot;)

if __name__ == &quot;__main__&quot;:
    main()


</code></pre>


</details>


## ğŸ¯ åº”ç”¨åœºæ™¯

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #2563eb;">ğŸ¤</div>
<h4 style="margin: 0 0 8px 0; color: #1e40af;">å¯¹è¯è§†é¢‘</h4>
<p style="margin: 0; color: #1e40af;">å°†é™æ€äººç‰©å›¾ç‰‡è½¬æ¢ä¸ºè¯´è¯è§†é¢‘</p>
</div>

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #059669;">ğŸµ</div>
<h4 style="margin: 0 0 8px 0; color: #059669;">éŸ³ä¹è§†é¢‘</h4>
<p style="margin: 0; color: #065f46;">åˆ›å»ºå”±æ­Œå’ŒéŸ³ä¹è¡¨æ¼”è§†é¢‘</p>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #ea580c;">ğŸ­</div>
<h4 style="margin: 0 0 8px 0; color: #ea580c;">è¡¨æ¼”è‰ºæœ¯</h4>
<p style="margin: 0; color: #9a3412;">ç”Ÿæˆå„ç§è¡¨æ¼”å’Œè‰ºæœ¯å†…å®¹</p>
</div>

<div style="background: #f5f3ff; border-left: 4px solid #7c3aed; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #7c3aed;">ğŸ“±</div>
<h4 style="margin: 0 0 8px 0; color: #7c3aed;">å†…å®¹åˆ›ä½œ</h4>
<p style="margin: 0; color: #5b21b6;">ç¤¾äº¤åª’ä½“å’Œæ•°å­—å†…å®¹åˆ¶ä½œ</p>
</div>

</div>

## ğŸ’¡ ä½¿ç”¨æŠ€å·§

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #dcfce7; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">âœ… æœ€ä½³å®è·µ</h4>
<ul style="margin: 0; padding-left: 20px; color: #065f46;">
  <li>ä½¿ç”¨æ¸…æ™°çš„äººç‰©å›¾ç‰‡ä½œä¸ºè¾“å…¥</li>
  <li>éŸ³é¢‘è´¨é‡è¶Šé«˜ï¼Œç”Ÿæˆæ•ˆæœè¶Šå¥½</li>
  <li>åˆç†è®¡ç®—è§†é¢‘æ‰©å±•èŠ‚ç‚¹æ•°é‡</li>
  <li>æ ¹æ®æ˜¾å­˜æƒ…å†µé€‰æ‹©åˆé€‚çš„æ¨¡å‹</li>
</ul>
</div>

<div style="background: #fef2f2; border-left: 4px solid #dc2626; padding: 16px; border-radius: 4px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">âš ï¸ æ³¨æ„äº‹é¡¹</h4>
<ul style="margin: 0; padding-left: 20px; color: #991b1b;">
  <li>Lightning LoRA ä¼šé™ä½è´¨é‡</li>
  <li>é•¿è§†é¢‘éœ€è¦æ›´å¤šè®¡ç®—èµ„æº</li>
  <li>ç¡®ä¿éŸ³é¢‘ç¼–ç å™¨æ–‡ä»¶å¤¹å­˜åœ¨</li>
  <li>æ‰¹å¤„ç†å¤§å°è¦ä¸æ‰©å±•èŠ‚ç‚¹åŒ¹é…</li>
</ul>
</div>

</div>

---

<div style="text-align: center; padding: 16px; background: #f8fafc; border-radius: 6px; margin-top: 24px;">
  <p style="margin: 0; color: #64748b; font-size: 14px;">
    ğŸµ <strong>Wan2.2-S2V éŸ³é¢‘é©±åŠ¨è§†é¢‘ç”Ÿæˆ</strong> | è®©é™æ€å›¾ç‰‡éšéŸ³é¢‘å¾‹åŠ¨èµ·æ¥
  </p>
  <p style="margin: 4px 0 0 0; color: #94a3b8; font-size: 12px;">
    Â© 2025 é€šä¹‰ä¸‡ç›¸å›¢é˜Ÿ | ComfyUI åŸç”Ÿæ”¯æŒ | å¼€å¯éŸ³é¢‘é©±åŠ¨è§†é¢‘åˆ›ä½œæ–°æ—¶ä»£
  </p>
</div>
        
      </div>

      <div class="copyrights">Â© 2009-2022 Aliyun.com ç‰ˆæƒæ‰€æœ‰</div>
    </div>
  </div>
  
  <!--
  MkDocs version      : 1.6.1
  Docs Build Date UTC : 2025-11-25 12:05:08.400046+00:00
  -->
</body>
</html>