<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="è®¡ç®—å·¢æ˜¯é˜¿é‡Œäº‘å¼€æ”¾ç»™ä¼ä¸šåº”ç”¨æœåŠ¡å•†çš„æœåŠ¡ç®¡ç†å¹³å°ã€‚æœåŠ¡å•†èƒ½å¤Ÿåœ¨è®¡ç®—å·¢ä¸Šå‘å¸ƒç§æœ‰åŒ–éƒ¨ç½²æœåŠ¡ï¼Œä¸ºå…¶å®¢æˆ·æä¾›äº‘ä¸Šè½¯ä»¶ä¸€é”®éƒ¨ç½²çš„èƒ½åŠ›ï¼›åŒæ—¶ä¹Ÿæ”¯æŒå…¨æ‰˜ç®¡æ¨¡å¼çš„æœåŠ¡ï¼Œèµ‹èƒ½æœåŠ¡å•†æ‰˜ç®¡å…¶å®¢æˆ·èµ„æºã€‚">
  <title>Index - Aliyun è®¡ç®—å·¢ x Demo</title>

  <link rel="shortcut icon" href="../../../img/favicon.ico">

  <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.0/build/pure-min.css">
  <link rel="stylesheet" href="../../../css/theme.css">
  

  

  
  

  
    <script src="../../../search/main.js"></script>
  

  

  <script src="../../../js/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>

<body>
  <div class="container">
    <div class="nav">
      <div class="nav-inner">
        <div class="logo">
          <img src="./img/logo-2x.png">
        </div>
        <div class="nav-list">
          <ul>
          
              <li><a href="#_1">ğŸ“‹ æ¨¡å‹æ¦‚è§ˆ</a></li>
              
          
              <li><a href="#wan22-fun-inp">ğŸš€ Wan2.2 Fun Inp å·¥ä½œæµç¤ºä¾‹</a></li>
              
                  <li><a href="#_2">ğŸ“¥ æ­¥éª¤ä¸€ï¼šå·¥ä½œæµæ–‡ä»¶ä¸‹è½½</a></li>
                  
              
                  <li><a href="#_3">ğŸ”— æ­¥éª¤äºŒï¼šæ¨¡å‹æ–‡ä»¶</a></li>
                  
                      <li class="li-h3"><a href="#_4">ğŸ“‚ æ¨¡å‹æ–‡ä»¶ç»“æ„</a></li>
                  
              
                  <li><a href="#_5">ğŸ”§ æ­¥éª¤ä¸‰ï¼šå·¥ä½œæµé…ç½®æ“ä½œ</a></li>
                  
              
          
              <li><a href="#api">APIè°ƒç”¨</a></li>
              
          
              <li><a href="#_6">ğŸ¯ åº”ç”¨åœºæ™¯</a></li>
              
          
              <li><a href="#_7">ğŸ’¡ ä½¿ç”¨æŠ€å·§ä¸å»ºè®®</a></li>
              
          
              <li><a href="#_8">ğŸ”§ æŠ€æœ¯è§„æ ¼</a></li>
              
          
          </ul>
        </div>
      </div>
    </div>
    <div class="content theme-github">
      
      <div class="content-inner">        
        
        <div style="background: linear-gradient(135deg, #2563eb, #1e40af); padding: 24px; border-radius: 8px; color: white; text-align: center; margin-bottom: 24px;">
  <h1 style="font-size: 2.5em; margin: 0; font-weight: 600;">ğŸ¬ Wan2.2-Fun-Inp é¦–å°¾å¸§è§†é¢‘ç”Ÿæˆ</h1>
  <p style="font-size: 1.2em; margin: 16px 0 0 0; opacity: 0.9;">ComfyUI åŸç”Ÿå·¥ä½œæµ - ç²¾ç¡®æ§åˆ¶è§†é¢‘é¦–å°¾å¸§çš„åˆ›æ„ç”Ÿæˆ</p>
  <div style="margin-top: 20px;">
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">ğŸ¯ é¦–å°¾å¸§æ§åˆ¶</span>
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">ğŸ¬ å½±è§†çº§è´¨é‡</span>
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">ğŸ“ å¤šåˆ†è¾¨ç‡</span>
  </div>
</div>

<h2 id="_1">ğŸ“‹ æ¨¡å‹æ¦‚è§ˆ</h2>
<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

**Wan2.2-Fun-Inp** æ˜¯ Alibaba PAI å›¢é˜Ÿæ¨å‡ºçš„é¦–å°¾å¸§æ§åˆ¶è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œæ”¯æŒè¾“å…¥**é¦–å¸§å’Œå°¾å¸§å›¾åƒ**ï¼Œç”Ÿæˆä¸­é—´è¿‡æ¸¡è§†é¢‘ï¼Œä¸ºåˆ›ä½œè€…å¸¦æ¥æ›´å¼ºçš„åˆ›æ„æ§åˆ¶åŠ›ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ **Apache 2.0 è®¸å¯åè®®**å‘å¸ƒï¼Œæ”¯æŒå•†ä¸šä½¿ç”¨ã€‚

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 16px; margin: 16px 0;">
  <div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
    <strong>ğŸ¯ é¦–å°¾å¸§æ§åˆ¶</strong><br>
    <p style="margin: 8px 0 0 0; color: #1e40af; font-size: 14px;">æ”¯æŒè¾“å…¥é¦–å¸§å’Œå°¾å¸§å›¾åƒï¼Œç”Ÿæˆä¸­é—´è¿‡æ¸¡è§†é¢‘</p>
  </div>

  <div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
    <strong>ğŸ¬ é«˜è´¨é‡è§†é¢‘ç”Ÿæˆ</strong><br>
    <p style="margin: 8px 0 0 0; color: #065f46; font-size: 14px;">åŸºäº Wan2.2 æ¶æ„ï¼Œè¾“å‡ºå½±è§†çº§è´¨é‡è§†é¢‘</p>
  </div>

  <div style="background: #fef3c7; border-left: 4px solid #d97706; padding: 16px; border-radius: 4px;">
    <strong>ğŸ“ å¤šåˆ†è¾¨ç‡æ”¯æŒ</strong><br>
    <p style="margin: 8px 0 0 0; color: #9a3412; font-size: 14px;">æ”¯æŒ 512Ã—512ã€768Ã—768ã€1024Ã—1024 ç­‰åˆ†è¾¨ç‡</p>
  </div>

  <div style="background: #f3e8ff; border-left: 4px solid #7c3aed; padding: 16px; border-radius: 4px;">
    <strong>âš¡ 14B é«˜æ€§èƒ½ç‰ˆ</strong><br>
    <p style="margin: 8px 0 0 0; color: #5b21b6; font-size: 14px;">æ¨¡å‹ä½“ç§¯è¾¾ 32GB+ï¼Œæ•ˆæœæ›´ä¼˜ä½†éœ€é«˜æ˜¾å­˜æ”¯æŒ</p>
  </div>
</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ğŸ”— ç›¸å…³èµ„æº</strong><br>
  â€¢ <strong>æ¨¡å‹ä»“åº“</strong>ï¼š<a href="https://huggingface.co/alibaba-pai/Wan2.2-Fun-A14B-InP" target="_blank" style="color: #2563eb;">ğŸ¤— Wan2.2-Fun-Inp-14B</a><br>
  â€¢ <strong>ä»£ç ä»“åº“</strong>ï¼š<a href="https://github.com/aigc-apps/VideoX-Fun" target="_blank" style="color: #2563eb;">VideoX-Fun</a>
</div>

</div>

<h2 id="wan22-fun-inp">ğŸš€ Wan2.2 Fun Inp å·¥ä½œæµç¤ºä¾‹</h2>
<h3 id="_2">ğŸ“¥ æ­¥éª¤ä¸€ï¼šå·¥ä½œæµæ–‡ä»¶ä¸‹è½½</h3>
<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">
æˆ–è€…ä½ å¯ä»¥ç›´æ¥é€šè¿‡Comfyuiè‡ªå¸¦çš„æ¨¡ç‰ˆä»“åº“æ‰“å¼€ï¼š

![img_1.png](img_1.png)
<div style="text-align: center; margin: 20px 0;">
  <video controls style="width: 100%; max-width: 800px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" src="https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/video/wan/wan2.2_fun_inp/wan2.2_14B_fun_inp.mp4"></video>
</div>

<div style="text-align: center; margin: 20px 0;">
  <a href="https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/video_wan2_2_14B_fun_inpaint.json" target="_blank" style="display: inline-block; background: linear-gradient(135deg, #2563eb, #1e40af); color: white; padding: 12px 24px; border-radius: 8px; text-decoration: none; font-weight: bold; box-shadow: 0 4px 8px rgba(37, 99, 235, 0.3);">
    ğŸ“„ ä¸‹è½½ JSON æ ¼å¼å·¥ä½œæµ
  </a>
</div>

### ğŸ“ ç¤ºä¾‹ç´ æä¸‹è½½

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 12px 0;">ğŸ–¼ï¸ é¦–å¸§å›¾åƒ</h4>
<div style="text-align: center; margin: 12px 0;">
  <img src="https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/video/wan/wan2.2_fun_inp/start_image.png" alt="é¦–å¸§ç´ æ" style="max-width: 100%; border-radius: 6px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
</div>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
<h4 style="color: #ea580c; margin: 0 0 12px 0;">ğŸ–¼ï¸ å°¾å¸§å›¾åƒ</h4>
<div style="text-align: center; margin: 12px 0;">
  <img src="https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/video/wan/wan2.2_fun_inp/end_image.png" alt="å°¾å¸§ç´ æ" style="max-width: 100%; border-radius: 6px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
</div>
</div>

</div>

</div>

<h3 id="_3">ğŸ”— æ­¥éª¤äºŒï¼šæ¨¡å‹æ–‡ä»¶</h3>
<h4 id="_4">ğŸ“‚ æ¨¡å‹æ–‡ä»¶ç»“æ„</h4>
<div style="background: #1e293b; border-radius: 6px; padding: 16px; margin: 16px 0;">
<pre style="margin: 0; color: #e2e8f0; font-family: 'Courier New', monospace; font-size: 14px;"><code>ComfyUI/
â”œâ”€â”€â”€ğŸ“‚ models/
â”‚   â”œâ”€â”€â”€ğŸ“‚ diffusion_models/
â”‚   â”‚   â”œâ”€â”€â”€ wan2.2_fun_inpaint_high_noise_14B_fp8_scaled.safetensors
â”‚   â”‚   â””â”€â”€â”€ wan2.2_fun_inpaint_low_noise_14B_fp8_scaled.safetensors
â”‚   â”œâ”€â”€â”€ğŸ“‚ loras/
â”‚   â”‚   â”œâ”€â”€â”€ wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors
â”‚   â”‚   â””â”€â”€â”€ wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors
â”‚   â”œâ”€â”€â”€ğŸ“‚ text_encoders/
â”‚   â”‚   â””â”€â”€â”€ umt5_xxl_fp8_e4m3fn_scaled.safetensors 
â”‚   â””â”€â”€â”€ğŸ“‚ vae/
â”‚       â””â”€â”€ wan_2.1_vae.safetensors</code></pre>
</div>

<h3 id="_5">ğŸ”§ æ­¥éª¤ä¸‰ï¼šå·¥ä½œæµé…ç½®æ“ä½œ</h3>
<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<div style="text-align: center; margin: 20px 0;">
  <img src="https://mintcdn.com/dripart/SIDaLac8vBogzwm7/images/tutorial/video/wan/wan2_2/wan_2.2_14b_fun_inp.jpg?fit=max&auto=format&n=SIDaLac8vBogzwm7&q=85&s=3d87de35d3eaa2f9599c35e9963c6c18" alt="å·¥ä½œæµé…ç½®æ­¥éª¤å›¾" style="width: 100%; max-width: 1200px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
</div>

<div style="background: #fef3c7; border-left: 4px solid #d97706; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>âš ï¸ é‡è¦æé†’</strong><br>
  æ­¤å·¥ä½œæµä½¿ç”¨äº† LoRA åŠ é€Ÿç‰ˆæœ¬ï¼Œè¯·ç¡®ä¿å¯¹åº”çš„ Diffusion Model å’Œ LoRA æ–‡ä»¶ä¿æŒä¸€è‡´ï¼ˆé«˜å™ªå£°å¯¹é«˜å™ªå£°ï¼Œä½å™ªå£°å¯¹ä½å™ªå£°ï¼‰ã€‚
</div>

#### ğŸ“‹ è¯¦ç»†é…ç½®æ­¥éª¤

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
<h4 style="color: #2563eb; margin: 0 0 12px 0;">ğŸ”§ High Noise æ¨¡å‹é…ç½®</h4>
<ul style="margin: 0; padding-left: 20px; color: #1e40af; font-size: 14px;">
  <li><strong>Load Diffusion Model</strong>ï¼š<br><code>wan2.2_fun_inpaint_high_noise_14B_fp8_scaled.safetensors</code></li>
  <li><strong>LoraLoaderModelOnly</strong>ï¼š<br><code>wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors</code></li>
</ul>
</div>

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 12px 0;">ğŸ”§ Low Noise æ¨¡å‹é…ç½®</h4>
<ul style="margin: 0; padding-left: 20px; color: #065f46; font-size: 14px;">
  <li><strong>Load Diffusion Model</strong>ï¼š<br><code>wan2.2_fun_inpaint_low_noise_14B_fp8_scaled.safetensors</code></li>
  <li><strong>LoraLoaderModelOnly</strong>ï¼š<br><code>wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors</code></li>
</ul>
</div>

</div>

#### ğŸ¯ åŸºç¡€æ¨¡å‹é…ç½®

<div style="overflow-x: auto; margin: 16px 0;">
<table style="width: 100%; border-collapse: collapse; background: white; border-radius: 6px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
  <thead style="background: #f8fafc;">
    <tr>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">èŠ‚ç‚¹åç§°</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">æ¨¡å‹æ–‡ä»¶</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">è¯´æ˜</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Load CLIP</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-family: monospace; font-size: 12px;">umt5_xxl_fp8_e4m3fn_scaled.safetensors</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">æ–‡æœ¬ç¼–ç å™¨</td>
    </tr>
    <tr>
      <td style="padding: 12px; font-weight: 500;">Load VAE</td>
      <td style="padding: 12px; font-family: monospace; font-size: 12px;">wan_2.1_vae.safetensors</td>
      <td style="padding: 12px;">å˜åˆ†è‡ªç¼–ç å™¨</td>
    </tr>
  </tbody>
</table>
</div>

#### ğŸ“ è¾“å…¥é…ç½®

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">ğŸ–¼ï¸ é¦–å°¾å¸§å›¾ç‰‡ä¸Šä¼ </h4>
<p style="margin: 0; color: #065f46; font-size: 14px;">åˆ†åˆ«ä¸Šä¼ é¦–å¸§å’Œå°¾å¸§å›¾ç‰‡ç´ æåˆ°å¯¹åº”çš„ Load Image èŠ‚ç‚¹</p>
</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
<h4 style="color: #2563eb; margin: 0 0 8px 0;">ğŸ“ æç¤ºè¯è¾“å…¥</h4>
<p style="margin: 0; color: #1e40af; font-size: 14px;">åœ¨ Prompt ç»„ä¸­è¾“å…¥æè¿°è§†é¢‘å†…å®¹çš„æç¤ºè¯</p>
</div>

</div>

#### âš™ï¸ å‚æ•°è°ƒæ•´

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ğŸ¬ WanFunInpaintToVideo èŠ‚ç‚¹é…ç½®</strong><br>
  â€¢ <strong>width & height</strong>ï¼šè°ƒæ•´è§†é¢‘å°ºå¯¸ï¼Œé»˜è®¤ä¸º 640Ã—640<br>
  â€¢ <strong>length</strong>ï¼šè®¾ç½®è§†é¢‘æ€»å¸§æ•°ï¼Œå½“å‰å·¥ä½œæµ fps ä¸º 16<br>
  â€¢ <strong>è®¡ç®—ç¤ºä¾‹</strong>ï¼šç”Ÿæˆ 5 ç§’è§†é¢‘éœ€è¦è®¾ç½® 5 Ã— 16 = 80 å¸§
</div>

#### ğŸš€ æ‰§è¡Œç”Ÿæˆ

<div style="text-align: center; margin: 20px 0;">
  <div style="background: linear-gradient(135deg, #059669, #047857); color: white; padding: 16px 32px; border-radius: 8px; display: inline-block; box-shadow: 0 4px 8px rgba(5, 150, 105, 0.3);">
    <strong>âŒ¨ï¸ ç‚¹å‡» Run æŒ‰é’®æˆ–ä½¿ç”¨å¿«æ·é”® Ctrl(Cmd) + Enter æ‰§è¡Œè§†é¢‘ç”Ÿæˆ</strong>
  </div>
</div>

</div>

<h2 id="api">APIè°ƒç”¨</h2>
<details style="border: 2px solid #2563eb; border-radius: 12px; padding: 20px; margin: 20px 0; background: linear-gradient(145deg, #f8fafc, #eff6ff); box-shadow: 0 8px 16px rgba(37, 99, 235, 0.15);">
<summary style="font-weight: bold; font-size: 18px; color: white; cursor: pointer; padding: 16px; background: linear-gradient(135deg, #2563eb, #1e40af); border-radius: 8px; margin: -20px -20px 20px -20px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); transition: all 0.3s ease; display: flex; align-items: center; box-shadow: 0 4px 8px rgba(37, 99, 235, 0.3);">
ğŸ“‹ ç‚¹å‡»å±•å¼€ComfyUI APIè°ƒç”¨Pythonä»£ç 
</summary>


<pre><code class="language-python">
import requests
import json
import uuid
import time
import random
import os

# Configuration Parameters - Wan2.2 First-Last Frame to Video Specific
COMFYUI_SERVER = &quot;127.0.0.1:8188&quot;  # Local server
COMFYUI_TOKEN = &quot;&quot;  # Usually no token needed for local

# Model Configuration
HIGH_NOISE_UNET = &quot;wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors&quot;
LOW_NOISE_UNET = &quot;wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors&quot;
CLIP_MODEL = &quot;umt5_xxl_fp8_e4m3fn_scaled.safetensors&quot;
VAE_MODEL = &quot;wan_2.1_vae.safetensors&quot;
HIGH_NOISE_LORA = &quot;wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors&quot;
LOW_NOISE_LORA = &quot;wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors&quot;

# Default Parameters
DEFAULT_POSITIVE_PROMPT = &quot;&quot;&quot;A bearded man with red facial hair wearing a yellow straw hat and dark coat in Van Gogh's self-portrait style, slowly and continuously transforms into a space astronaut. The transformation flows like liquid paint - his beard fades away strand by strand, the yellow hat melts and reforms smoothly into a silver space helmet, dark coat gradually lightens and restructures into a white spacesuit. The background swirling brushstrokes slowly organize and clarify into realistic stars and space, with Earth appearing gradually in the distance. Every change happens in seamless waves, maintaining visual continuity throughout the metamorphosis.

Consistent soft lighting throughout, medium close-up maintaining same framing, central composition stays fixed, gentle color temperature shift from warm to cool, gradual contrast increase, smooth style transition from painterly to photorealistic. Static camera with subtle slow zoom, emphasizing the flowing transformation process without abrupt changes.&quot;&quot;&quot;

DEFAULT_NEGATIVE_PROMPT = &quot;è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°&quot;

DEFAULT_START_IMAGE = &quot;ComfyUI_00592_.png&quot;
DEFAULT_END_IMAGE = &quot;Qwen-Image_00002_.png&quot;

class ComfyUIWan22FirstLastFrameClient:
    def __init__(self, server=COMFYUI_SERVER, token=COMFYUI_TOKEN):
        self.base_url = f&quot;http://{server}&quot;
        self.token = token
        self.client_id = str(uuid.uuid4())
        self.headers = {&quot;Content-Type&quot;: &quot;application/json&quot;}
        if token:
            self.headers[&quot;Authorization&quot;] = f&quot;Bearer {token}&quot;

    def upload_image(self, image_path):
        &quot;&quot;&quot;Upload image to ComfyUI server&quot;&quot;&quot;
        try:
            with open(image_path, 'rb') as f:
                files = {'image': f}
                response = requests.post(f&quot;{self.base_url}/upload/image&quot;, files=files)
                if response.status_code == 200:
                    result = response.json()
                    return result.get('name', os.path.basename(image_path))
                else:
                    raise Exception(f&quot;Failed to upload image: {response.text}&quot;)
        except Exception as e:
            print(f&quot;Image upload error: {e}&quot;)
            return None

    def generate_first_last_frame_video(self, positive_prompt, negative_prompt=None,
                                       start_image_path=None, start_image_name=None,
                                       end_image_path=None, end_image_name=None,
                                       width=640, height=640, length=81, fps=16,
                                       steps=4, cfg=1, seed=None, shift=5.0,
                                       lora_strength=1.0):
        &quot;&quot;&quot;Generate First-Last Frame video using Wan2.2 based on original JSON workflow&quot;&quot;&quot;
        print(&quot;Starting Wan2.2 First-Last Frame to Video generation...&quot;)

        # Use default negative prompt if not provided
        if negative_prompt is None:
            negative_prompt = DEFAULT_NEGATIVE_PROMPT

        # Generate random seed if not provided
        if seed is None:
            seed = random.randint(1, 1000000000000000)

        # Handle start image
        if start_image_path and not start_image_name:
            start_image_name = self.upload_image(start_image_path)
            if not start_image_name:
                raise Exception(&quot;Failed to upload start image&quot;)
        elif not start_image_name:
            start_image_name = DEFAULT_START_IMAGE

        # Handle end image
        if end_image_path and not end_image_name:
            end_image_name = self.upload_image(end_image_path)
            if not end_image_name:
                raise Exception(&quot;Failed to upload end image&quot;)
        elif not end_image_name:
            end_image_name = DEFAULT_END_IMAGE

        # Workflow based on your provided JSON
        workflow = {
            &quot;6&quot;: {
                &quot;inputs&quot;: {
                    &quot;text&quot;: positive_prompt,
                    &quot;clip&quot;: [&quot;38&quot;, 0]
                },
                &quot;class_type&quot;: &quot;CLIPTextEncode&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;CLIP Text Encode (Positive Prompt)&quot;}
            },
            &quot;7&quot;: {
                &quot;inputs&quot;: {
                    &quot;text&quot;: negative_prompt,
                    &quot;clip&quot;: [&quot;38&quot;, 0]
                },
                &quot;class_type&quot;: &quot;CLIPTextEncode&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;CLIP Text Encode (Negative Prompt)&quot;}
            },
            &quot;8&quot;: {
                &quot;inputs&quot;: {
                    &quot;samples&quot;: [&quot;58&quot;, 0],
                    &quot;vae&quot;: [&quot;39&quot;, 0]
                },
                &quot;class_type&quot;: &quot;VAEDecode&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;VAE Decode&quot;}
            },
            &quot;37&quot;: {
                &quot;inputs&quot;: {
                    &quot;unet_name&quot;: HIGH_NOISE_UNET,
                    &quot;weight_dtype&quot;: &quot;default&quot;
                },
                &quot;class_type&quot;: &quot;UNETLoader&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;UNet Loader (High Noise)&quot;}
            },
            &quot;38&quot;: {
                &quot;inputs&quot;: {
                    &quot;clip_name&quot;: CLIP_MODEL,
                    &quot;type&quot;: &quot;wan&quot;,
                    &quot;device&quot;: &quot;default&quot;
                },
                &quot;class_type&quot;: &quot;CLIPLoader&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;CLIP Loader&quot;}
            },
            &quot;39&quot;: {
                &quot;inputs&quot;: {
                    &quot;vae_name&quot;: VAE_MODEL
                },
                &quot;class_type&quot;: &quot;VAELoader&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;VAE Loader&quot;}
            },
            &quot;54&quot;: {
                &quot;inputs&quot;: {
                    &quot;shift&quot;: shift,
                    &quot;model&quot;: [&quot;91&quot;, 0]
                },
                &quot;class_type&quot;: &quot;ModelSamplingSD3&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Model Sampling SD3 (High Noise)&quot;}
            },
            &quot;55&quot;: {
                &quot;inputs&quot;: {
                    &quot;shift&quot;: shift,
                    &quot;model&quot;: [&quot;92&quot;, 0]
                },
                &quot;class_type&quot;: &quot;ModelSamplingSD3&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Model Sampling SD3 (Low Noise)&quot;}
            },
            &quot;56&quot;: {
                &quot;inputs&quot;: {
                    &quot;unet_name&quot;: LOW_NOISE_UNET,
                    &quot;weight_dtype&quot;: &quot;default&quot;
                },
                &quot;class_type&quot;: &quot;UNETLoader&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;UNet Loader (Low Noise)&quot;}
            },
            &quot;57&quot;: {
                &quot;inputs&quot;: {
                    &quot;add_noise&quot;: &quot;enable&quot;,
                    &quot;noise_seed&quot;: seed,
                    &quot;steps&quot;: steps,
                    &quot;cfg&quot;: cfg,
                    &quot;sampler_name&quot;: &quot;euler&quot;,
                    &quot;scheduler&quot;: &quot;simple&quot;,
                    &quot;start_at_step&quot;: 0,
                    &quot;end_at_step&quot;: 2,
                    &quot;return_with_leftover_noise&quot;: &quot;enable&quot;,
                    &quot;model&quot;: [&quot;54&quot;, 0],
                    &quot;positive&quot;: [&quot;67&quot;, 0],
                    &quot;negative&quot;: [&quot;67&quot;, 1],
                    &quot;latent_image&quot;: [&quot;67&quot;, 2]
                },
                &quot;class_type&quot;: &quot;KSamplerAdvanced&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;K Sampler Advanced (High Noise Stage)&quot;}
            },
            &quot;58&quot;: {
                &quot;inputs&quot;: {
                    &quot;add_noise&quot;: &quot;disable&quot;,
                    &quot;noise_seed&quot;: 0,
                    &quot;steps&quot;: steps,
                    &quot;cfg&quot;: cfg,
                    &quot;sampler_name&quot;: &quot;euler&quot;,
                    &quot;scheduler&quot;: &quot;simple&quot;,
                    &quot;start_at_step&quot;: 2,
                    &quot;end_at_step&quot;: 10000,
                    &quot;return_with_leftover_noise&quot;: &quot;disable&quot;,
                    &quot;model&quot;: [&quot;55&quot;, 0],
                    &quot;positive&quot;: [&quot;67&quot;, 0],
                    &quot;negative&quot;: [&quot;67&quot;, 1],
                    &quot;latent_image&quot;: [&quot;57&quot;, 0]
                },
                &quot;class_type&quot;: &quot;KSamplerAdvanced&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;K Sampler Advanced (Low Noise Stage)&quot;}
            },
            &quot;60&quot;: {
                &quot;inputs&quot;: {
                    &quot;fps&quot;: fps,
                    &quot;images&quot;: [&quot;8&quot;, 0]
                },
                &quot;class_type&quot;: &quot;CreateVideo&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Create Video&quot;}
            },
            &quot;61&quot;: {
                &quot;inputs&quot;: {
                    &quot;filename_prefix&quot;: &quot;wan22_first_last_frame/video&quot;,
                    &quot;format&quot;: &quot;auto&quot;,
                    &quot;codec&quot;: &quot;auto&quot;,
                    &quot;video&quot;: [&quot;60&quot;, 0]
                },
                &quot;class_type&quot;: &quot;SaveVideo&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Save Video&quot;}
            },
            &quot;62&quot;: {
                &quot;inputs&quot;: {
                    &quot;image&quot;: end_image_name
                },
                &quot;class_type&quot;: &quot;LoadImage&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Load End Image&quot;}
            },
            &quot;67&quot;: {
                &quot;inputs&quot;: {
                    &quot;width&quot;: width,
                    &quot;height&quot;: height,
                    &quot;length&quot;: length,
                    &quot;batch_size&quot;: 1,
                    &quot;positive&quot;: [&quot;6&quot;, 0],
                    &quot;negative&quot;: [&quot;7&quot;, 0],
                    &quot;vae&quot;: [&quot;39&quot;, 0],
                    &quot;start_image&quot;: [&quot;68&quot;, 0],
                    &quot;end_image&quot;: [&quot;62&quot;, 0]
                },
                &quot;class_type&quot;: &quot;WanFirstLastFrameToVideo&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Wan First Last Frame To Video&quot;}
            },
            &quot;68&quot;: {
                &quot;inputs&quot;: {
                    &quot;image&quot;: start_image_name
                },
                &quot;class_type&quot;: &quot;LoadImage&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;Load Start Image&quot;}
            },
            &quot;91&quot;: {
                &quot;inputs&quot;: {
                    &quot;lora_name&quot;: HIGH_NOISE_LORA,
                    &quot;strength_model&quot;: lora_strength,
                    &quot;model&quot;: [&quot;37&quot;, 0]
                },
                &quot;class_type&quot;: &quot;LoraLoaderModelOnly&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;LoRA Loader (High Noise)&quot;}
            },
            &quot;92&quot;: {
                &quot;inputs&quot;: {
                    &quot;lora_name&quot;: LOW_NOISE_LORA,
                    &quot;strength_model&quot;: lora_strength,
                    &quot;model&quot;: [&quot;56&quot;, 0]
                },
                &quot;class_type&quot;: &quot;LoraLoaderModelOnly&quot;,
                &quot;_meta&quot;: {&quot;title&quot;: &quot;LoRA Loader (Low Noise)&quot;}
            }
        }

        print(&quot;Submitting Wan2.2 First-Last Frame to Video generation workflow...&quot;)
        print(f&quot;Positive Prompt: {positive_prompt[:100]}...&quot;)
        print(f&quot;Start Image: {start_image_name}&quot;)
        print(f&quot;End Image: {end_image_name}&quot;)
        print(f&quot;Video Dimensions: {width}x{height}&quot;)
        print(f&quot;Video Length: {length} frames&quot;)
        print(f&quot;FPS: {fps}&quot;)
        print(f&quot;Steps: {steps}&quot;)
        print(f&quot;CFG: {cfg}&quot;)
        print(f&quot;Seed: {seed}&quot;)
        print(f&quot;Shift: {shift}&quot;)

        response = requests.post(
            f&quot;{self.base_url}/prompt&quot;, 
            headers=self.headers, 
            json={&quot;prompt&quot;: workflow, &quot;client_id&quot;: self.client_id}
        )

        print(f&quot;API Response: {response.text}&quot;)

        if response.status_code != 200:
            raise Exception(f&quot;API request failed with status code: {response.status_code}&quot;)

        result = response.json()
        if &quot;error&quot; in result:
            raise Exception(f&quot;Workflow error: {result['error']}&quot;)
        if &quot;prompt_id&quot; not in result:
            raise Exception(f&quot;No prompt_id in response: {result}&quot;)

        return result[&quot;prompt_id&quot;], seed

    def get_status(self, task_id):
        &quot;&quot;&quot;Get task status&quot;&quot;&quot;
        try:
            # Check queue status
            queue_data = requests.get(f&quot;{self.base_url}/queue&quot;, headers=self.headers).json()

            # Check if in running queue
            if any(item[1] == task_id for item in queue_data.get(&quot;queue_running&quot;, [])):
                return &quot;processing&quot;

            # Check if in pending queue
            if any(item[1] == task_id for item in queue_data.get(&quot;queue_pending&quot;, [])):
                return &quot;pending&quot;

            # Check history
            history_response = requests.get(f&quot;{self.base_url}/history/{task_id}&quot;, headers=self.headers)
            if history_response.status_code == 200:
                history = history_response.json()
                if task_id in history:
                    return &quot;completed&quot;

            return &quot;processing&quot;
        except Exception as e:
            print(f&quot;Status check error: {e}&quot;)
            return &quot;processing&quot;

    def download_video(self, task_id, output_dir=&quot;outputs&quot;):
        &quot;&quot;&quot;Download generated video files&quot;&quot;&quot;
        try:
            # Ensure output directory exists
            os.makedirs(output_dir, exist_ok=True)

            response = requests.get(f&quot;{self.base_url}/history/{task_id}&quot;, headers=self.headers)
            history = response.json()

            if task_id in history:
                outputs = history[task_id]['outputs']
                downloaded_files = []

                for node_id, output in outputs.items():
                    # Check for video files
                    if 'videos' in output:
                        for video_info in output['videos']:
                            filename = video_info['filename']
                            # Download video
                            video_response = requests.get(
                                f&quot;{self.base_url}/view?filename={filename}&quot;, 
                                headers=self.headers
                            )

                            if video_response.status_code == 200:
                                output_path = os.path.join(output_dir, filename)
                                with open(output_path, &quot;wb&quot;) as f:
                                    f.write(video_response.content)
                                downloaded_files.append(output_path)
                                print(f&quot;Video saved: {output_path}&quot;)

                    # Check for preview images
                    if 'images' in output:
                        for img_info in output['images']:
                            filename = img_info['filename']
                            # Download preview image
                            img_response = requests.get(
                                f&quot;{self.base_url}/view?filename={filename}&quot;, 
                                headers=self.headers
                            )

                            if img_response.status_code == 200:
                                output_path = os.path.join(output_dir, filename)
                                with open(output_path, &quot;wb&quot;) as f:
                                    f.write(img_response.content)
                                downloaded_files.append(output_path)
                                print(f&quot;Preview image saved: {output_path}&quot;)

                return downloaded_files

        except Exception as e:
            print(f&quot;Download error: {e}&quot;)

        return []

    def generate_batch(self, configs, **kwargs):
        &quot;&quot;&quot;Batch generate first-last frame videos with different configurations&quot;&quot;&quot;
        results = []

        for i, config in enumerate(configs):
            print(f&quot;\nStarting First-Last Frame video generation task {i+1}/{len(configs)}...&quot;)

            try:
                task_id, seed = self.generate_first_last_frame_video(**config, **kwargs)

                # Wait for completion
                while True:
                    status = self.get_status(task_id)
                    print(f&quot;Task {i+1} status: {status}&quot;)

                    if status == &quot;completed&quot;:
                        files = self.download_video(task_id)
                        results.append({
                            'task_id': task_id,
                            'seed': seed,
                            'files': files,
                            'config': config
                        })
                        break
                    elif status == &quot;failed&quot;:
                        print(f&quot;Task {i+1} failed&quot;)
                        break

                    time.sleep(15)  # Video generation takes time

            except Exception as e:
                print(f&quot;Task {i+1} error: {e}&quot;)

        return results

    def generate_transformation_sequence(self, start_image_path, end_image_path, 
                                       transformation_prompt, length_preset=&quot;medium&quot;):
        &quot;&quot;&quot;Generate transformation video with predefined length settings&quot;&quot;&quot;
        length_presets = {
            &quot;short&quot;: {&quot;length&quot;: 49, &quot;fps&quot;: 12},
            &quot;medium&quot;: {&quot;length&quot;: 81, &quot;fps&quot;: 16},
            &quot;long&quot;: {&quot;length&quot;: 121, &quot;fps&quot;: 20},
            &quot;extra_long&quot;: {&quot;length&quot;: 161, &quot;fps&quot;: 24}
        }

        settings = length_presets.get(length_preset, length_presets[&quot;medium&quot;])
        return self.generate_first_last_frame_video(
            positive_prompt=transformation_prompt,
            start_image_path=start_image_path,
            end_image_path=end_image_path,
            **settings
        )

    def generate_morphing_video(self, image_pairs, base_prompt_template):
        &quot;&quot;&quot;Generate multiple morphing videos from image pairs&quot;&quot;&quot;
        results = []

        for i, (start_img, end_img, description) in enumerate(image_pairs):
            prompt = base_prompt_template.format(description=description)
            print(f&quot;\nGenerating morphing video {i+1}: {description}&quot;)

            try:
                task_id, seed = self.generate_first_last_frame_video(
                    positive_prompt=prompt,
                    start_image_path=start_img,
                    end_image_path=end_img
                )

                # Wait for completion
                while True:
                    status = self.get_status(task_id)
                    if status == &quot;completed&quot;:
                        files = self.download_video(task_id)
                        results.append({
                            'description': description,
                            'files': files,
                            'start_image': start_img,
                            'end_image': end_img
                        })
                        break
                    elif status == &quot;failed&quot;:
                        print(f&quot;Morphing video {i+1} failed&quot;)
                        break
                    time.sleep(15)

            except Exception as e:
                print(f&quot;Morphing video {i+1} error: {e}&quot;)

        return results

def main():
    &quot;&quot;&quot;Main function - Execute Wan2.2 First-Last Frame to Video generation&quot;&quot;&quot;
    client = ComfyUIWan22FirstLastFrameClient()

    try:
        print(&quot;Wan2.2 First-Last Frame to Video generation client started...&quot;)

        # Single transformation video generation example
        print(&quot;\n=== Single Transformation Video Generation ===&quot;)

        # You can provide local file paths or use existing file names
        start_image_path = None  # Set to your start image path, e.g., &quot;start.jpg&quot;
        end_image_path = None    # Set to your end image path, e.g., &quot;end.jpg&quot;

        task_id, seed = client.generate_first_last_frame_video(
            positive_prompt=DEFAULT_POSITIVE_PROMPT,
            negative_prompt=DEFAULT_NEGATIVE_PROMPT,
            start_image_path=start_image_path,
            start_image_name=DEFAULT_START_IMAGE,
            end_image_path=end_image_path,
            end_image_name=DEFAULT_END_IMAGE,
            width=640,
            height=640,
            length=81,
            fps=16,
            steps=4,
            cfg=1,
            shift=5.0
        )

        print(f&quot;Task ID: {task_id}&quot;)
        print(f&quot;Seed: {seed}&quot;)

        # Wait for task completion
        while True:
            status = client.get_status(task_id)
            print(f&quot;Current status: {status}&quot;)

            if status == &quot;completed&quot;:
                print(&quot;First-Last Frame video generation completed!&quot;)
                break
            elif status == &quot;failed&quot;:
                print(&quot;Generation failed!&quot;)
                return

            time.sleep(15)

        # Download video files
        downloaded_files = client.download_video(task_id)
        if downloaded_files:
            print(f&quot;Successfully downloaded {len(downloaded_files)} files!&quot;)
            for file in downloaded_files:
                print(f&quot;File path: {file}&quot;)
        else:
            print(&quot;Download failed&quot;)

        # Transformation sequence example
        print(&quot;\n=== Transformation Sequence Example ===&quot;)
        # Uncomment to test different transformation lengths
        # if start_image_path and end_image_path:
        #     for preset in [&quot;short&quot;, &quot;medium&quot;, &quot;long&quot;]:
        #         print(f&quot;Generating {preset} transformation...&quot;)
        #         task_id, seed = client.generate_transformation_sequence(
        #             start_image_path, end_image_path, 
        #             &quot;Smooth transformation between two states&quot;, preset
        #         )
        #         # Wait and download logic here...

        # Morphing video example
        print(&quot;\n=== Morphing Video Example ===&quot;)
        # image_pairs = [
        #     (&quot;portrait1.jpg&quot;, &quot;portrait2.jpg&quot;, &quot;person transforms into another person&quot;),
        #     (&quot;cat.jpg&quot;, &quot;dog.jpg&quot;, &quot;cat slowly morphs into a dog&quot;),
        #     (&quot;day.jpg&quot;, &quot;night.jpg&quot;, &quot;day scene transitions to night scene&quot;)
        # ]
        # 
        # prompt_template = &quot;Smooth and seamless transformation where {description}. &quot; \
        #                  &quot;The change happens gradually with flowing motion, maintaining &quot; \
        #                  &quot;visual continuity throughout the metamorphosis.&quot;
        # 
        # morphing_results = client.generate_morphing_video(image_pairs, prompt_template)
        # print(f&quot;Generated {len(morphing_results)} morphing videos&quot;)

        # Batch generation example
        print(&quot;\n=== Batch Generation Example ===&quot;)
        batch_configs = [
            {
                'positive_prompt': &quot;A flower blooming from bud to full bloom, time-lapse style transformation&quot;,
                'start_image_name': DEFAULT_START_IMAGE,
                'end_image_name': DEFAULT_END_IMAGE,
                'length': 49,
                'fps': 12
            },
            {
                'positive_prompt': &quot;Sunset to sunrise transformation, smooth color transition in the sky&quot;,
                'start_image_name': DEFAULT_START_IMAGE,
                'end_image_name': DEFAULT_END_IMAGE,
                'length': 81,
                'fps': 16
            }
        ]

        # Uncomment to run batch generation
        # batch_results = client.generate_batch(batch_configs, steps=4, cfg=1)
        # print(f&quot;Batch generation completed, generated {len(batch_results)} videos&quot;)

    except Exception as e:
        print(f&quot;Error: {e}&quot;)

if __name__ == &quot;__main__&quot;:
    main()


</code></pre>


</details>

<h2 id="_6">ğŸ¯ åº”ç”¨åœºæ™¯</h2>
<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #2563eb;">ğŸ¬</div>
<h4 style="margin: 0 0 8px 0; color: #1e40af;">å½±è§†åˆ¶ä½œ</h4>
<p style="margin: 0; color: #1e40af;">ç²¾ç¡®æ§åˆ¶åœºæ™¯è½¬æ¢å’Œé•œå¤´è¿‡æ¸¡</p>
</div>

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #059669;">ğŸ¨</div>
<h4 style="margin: 0 0 8px 0; color: #059669;">åˆ›æ„åŠ¨ç”»</h4>
<p style="margin: 0; color: #065f46;">è‰ºæœ¯åˆ›ä½œå’Œæ¦‚å¿µè®¾è®¡å¯è§†åŒ–</p>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #ea580c;">ğŸ“±</div>
<h4 style="margin: 0 0 8px 0; color: #ea580c;">ç¤¾äº¤åª’ä½“</h4>
<p style="margin: 0; color: #9a3412;">çŸ­è§†é¢‘å†…å®¹å’Œè¥é”€ç´ æåˆ¶ä½œ</p>
</div>

<div style="background: #f5f3ff; border-left: 4px solid #7c3aed; padding: 16px; border-radius: 4px; text-align: center;">
<div style="font-size: 2.5em; margin-bottom: 12px; color: #7c3aed;">ğŸ®</div>
<h4 style="margin: 0 0 8px 0; color: #7c3aed;">æ¸¸æˆå¼€å‘</h4>
<p style="margin: 0; color: #5b21b6;">æ¸¸æˆåŠ¨ç”»å’Œè¿‡åœºåŠ¨ç”»åˆ¶ä½œ</p>
</div>

</div>

<h2 id="_7">ğŸ’¡ ä½¿ç”¨æŠ€å·§ä¸å»ºè®®</h2>
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #dcfce7; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">âœ… æœ€ä½³å®è·µ</h4>
<ul style="margin: 0; padding-left: 20px; color: #065f46;">
  <li>é¦–å°¾å¸§å›¾åƒä¿æŒé£æ ¼ä¸€è‡´æ€§</li>
  <li>é€‰æ‹©åˆé€‚çš„åˆ†è¾¨ç‡å¹³è¡¡è´¨é‡ä¸æ€§èƒ½</li>
  <li>æ ¹æ®æ˜¾å­˜æƒ…å†µé€‰æ‹©åˆé€‚çš„æ¨¡å‹ç‰ˆæœ¬</li>
  <li>æç¤ºè¯è¦å‡†ç¡®æè¿°è¿‡æ¸¡è¿‡ç¨‹</li>
</ul>
</div>

<div style="background: #fef2f2; border-left: 4px solid #dc2626; padding: 16px; border-radius: 4px;">
<h4 style="color: #dc2626; margin: 0 0 8px 0;">âš ï¸ æ³¨æ„äº‹é¡¹</h4>
<ul style="margin: 0; padding-left: 20px; color: #991b1b;">
  <li>ç¡®ä¿ High/Low Noise æ¨¡å‹ä¸ LoRA åŒ¹é…</li>
  <li>Lightning LoRA ä¼šç‰ºç‰²éƒ¨åˆ†åŠ¨æ€æ•ˆæœ</li>
  <li>é•¿è§†é¢‘ç”Ÿæˆéœ€è¦æ›´å¤šè®¡ç®—èµ„æº</li>
  <li>é¦–å°¾å¸§å·®å¼‚è¿‡å¤§å¯èƒ½å½±å“è¿‡æ¸¡æ•ˆæœ</li>
</ul>
</div>

</div>

<h2 id="_8">ğŸ”§ æŠ€æœ¯è§„æ ¼</h2>
<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

### ğŸ’» ç³»ç»Ÿè¦æ±‚

<div style="overflow-x: auto; margin: 16px 0;">
<table style="width: 100%; border-collapse: collapse; background: white; border-radius: 6px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
  <thead style="background: #f8fafc;">
    <tr>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">é…ç½®é¡¹</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">æœ€ä½è¦æ±‚</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">æ¨èé…ç½®</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">GPU æ˜¾å­˜</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">20GB</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">24GB+</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">ç³»ç»Ÿå†…å­˜</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">32GB</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">64GB+</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">å­˜å‚¨ç©ºé—´</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">50GB</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">100GB+ SSD</td>
    </tr>
    <tr>
      <td style="padding: 12px; font-weight: 500;">æ¨è GPU</td>
      <td style="padding: 12px;">RTX 4090</td>
      <td style="padding: 12px;">RTX 4090 / A100</td>
    </tr>
  </tbody>
</table>
</div>

### ğŸ“ æ”¯æŒåˆ†è¾¨ç‡

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 12px; margin: 16px 0;">
  <div style="background: #eff6ff; padding: 12px; border-radius: 6px; text-align: center;">
    <span style="background: #2563eb; color: white; padding: 4px 12px; border-radius: 12px; font-size: 12px;">512Ã—512</span>
  </div>
  <div style="background: #f0fdf4; padding: 12px; border-radius: 6px; text-align: center;">
    <span style="background: #059669; color: white; padding: 4px 12px; border-radius: 12px; font-size: 12px;">640Ã—640</span>
  </div>
  <div style="background: #fff7ed; padding: 12px; border-radius: 6px; text-align: center;">
    <span style="background: #ea580c; color: white; padding: 4px 12px; border-radius: 12px; font-size: 12px;">768Ã—768</span>
  </div>
  <div style="background: #f3e8ff; padding: 12px; border-radius: 6px; text-align: center;">
    <span style="background: #7c3aed; color: white; padding: 4px 12px; border-radius: 12px; font-size: 12px;">1024Ã—1024</span>
  </div>
</div>

</div>

<hr />
<div style="text-align: center; padding: 16px; background: #f8fafc; border-radius: 6px; margin-top: 24px;">
  <p style="margin: 0; color: #64748b; font-size: 14px;">
    ğŸ¬ <strong>Wan2.2-Fun-Inp é¦–å°¾å¸§è§†é¢‘ç”Ÿæˆ</strong> | ç²¾ç¡®æ§åˆ¶æ¯ä¸€å¸§çš„åˆ›æ„è¡¨è¾¾
  </p>
  <p style="margin: 4px 0 0 0; color: #94a3b8; font-size: 12px;">
    Â© 2025 Alibaba PAI å›¢é˜Ÿ | Apache 2.0 å¼€æºåè®® | è®©åˆ›æ„åœ¨é¦–å°¾ä¹‹é—´è‡ªç”±æµæ·Œ
  </p>
</div>
        
      </div>

      <div class="copyrights">Â© 2009-2022 Aliyun.com ç‰ˆæƒæ‰€æœ‰</div>
    </div>
  </div>
  
  <!--
  MkDocs version      : 1.6.1
  Docs Build Date UTC : 2025-11-25 12:05:08.459870+00:00
  -->
</body>
</html>