<div style="background: linear-gradient(135deg, #2563eb, #1e40af); padding: 24px; border-radius: 8px; color: white; text-align: center; margin-bottom: 24px;">
  <h2 style="margin: 0; color: white;">ðŸ§  DeepSeek-R1 Reasoning Model</h2>
  <p style="margin: 8px 0 0 0; opacity: 0.9;">671 Billion Parameter Reasoning Expert - Open Source Challenger to OpenAI o1</p>
</div>

## ðŸŽ¯ Product Overview

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

DeepSeek-R1 is a large language model (LLM) developed by Hangzhou DeepSeek Company, specifically optimized for tasks such as mathematics, coding, and logical reasoning. It adopts advanced technologies including Mixture of Experts (MoE) and Multi-Head Latent Attention (MLA), with **671 billion parameters** and support for input contexts up to **128,000 tokens**.

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ðŸŽ¯ Core Objective</strong><br>
  DeepSeek-R1 aims to match or exceed the performance of OpenAI's o1 model in reasoning tasks, providing world-class reasoning capabilities to the open source community.
</div>

</div>

## âœ¨ Core Features

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 16px; margin: 16px 0;">

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
  <strong>ðŸš€ Powerful Reasoning Capabilities</strong><br>
  Outstanding performance in mathematics, code generation, and natural language reasoning tasks, even surpassing similar models, demonstrating excellent logical thinking abilities.
</div>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
  <strong>âš¡ MoE Architecture Advantages</strong><br>
  Adopts mixture of experts model, using numerous experts in each layer to handle different inputs, significantly improving reasoning capabilities and processing efficiency.
</div>

<div style="background: #fef7ff; border-left: 4px solid #a855f7; padding: 16px; border-radius: 4px;">
  <strong>ðŸ“š Long Context Support</strong><br>
  Can handle longer input contexts (128,000 tokens), which is crucial for complex reasoning tasks and long document analysis.
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
  <strong>ðŸ”“ Fully Open Source</strong><br>
  DeepSeek Company has completely open-sourced DeepSeek-R1's training techniques and model weights, enabling developers to conduct further exploration and research.
</div>

<div style="background: #ecfdf5; border-left: 4px solid #10b981; padding: 16px; border-radius: 4px;">
  <strong>ðŸŽ“ Open Source Distilled Models</strong><br>
  Through distillation techniques, generated 6 smaller models (such as Qwen2.5 and Llama3.1) for community use, lowering deployment barriers.
</div>

</div>

## ðŸŽ“ Distilled Model Ecosystem

<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

<h3 style="margin-top: 0; color: #1e40af;">ðŸ“¦ Open Source Distilled Model Series</h3>

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>ðŸŽ¯ Distillation Strategy</strong><br>
  Through advanced distillation techniques, DeepSeek-R1's reasoning capabilities are transferred to smaller models, generating 6 lightweight versions for community use.
</div>

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 12px; margin: 16px 0;">

<div style="background: white; padding: 12px; border-radius: 6px; border: 1px solid #e2e8f0; text-align: center;">
  <div style="background: #dbeafe; color: #2563eb; padding: 6px 12px; border-radius: 4px; font-weight: 600; margin-bottom: 8px;">Qwen2.5 Series</div>
  <div style="color: #64748b; font-size: 14px;">High-performance distilled version</div>
</div>

<div style="background: white; padding: 12px; border-radius: 6px; border: 1px solid #e2e8f0; text-align: center;">
  <div style="background: #dcfce7; color: #059669; padding: 6px 12px; border-radius: 4px; font-weight: 600; margin-bottom: 8px;">Llama3.1 Series</div>
  <div style="color: #64748b; font-size: 14px;">Compatibility optimized version</div>
</div>

<div style="background: white; padding: 12px; border-radius: 6px; border: 1px solid #e2e8f0; text-align: center;">
  <div style="background: #fed7aa; color: #ea580c; padding: 6px 12px; border-radius: 4px; font-weight: 600; margin-bottom: 8px;">Lightweight Models</div>
  <div style="color: #64748b; font-size: 14px;">Edge deployment friendly</div>
</div>

<div style="background: white; padding: 12px; border-radius: 6px; border: 1px solid #e2e8f0; text-align: center;">
  <div style="background: #f3e8ff; color: #a855f7; padding: 6px 12px; border-radius: 4px; font-weight: 600; margin-bottom: 8px;">Customized Versions</div>
  <div style="color: #64748b; font-size: 14px;">Specific scenario optimization</div>
</div>

</div>

</div>

{% include './docs/template/llm-instructions-en.md' %}

---

<div style="text-align: center; padding: 16px; background: #f8fafc; border-radius: 6px; margin-top: 24px;">
  <p style="margin: 0; color: #64748b; font-size: 14px;">
    ðŸ§  <strong>DeepSeek-R1</strong> | 671 Billion Parameter Reasoning Expert, Open Source Challenger to OpenAI o1
  </p>
</div>