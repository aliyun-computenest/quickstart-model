<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="计算巢是阿里云开放给企业应用服务商的服务管理平台。服务商能够在计算巢上发布私有化部署服务，为其客户提供云上软件一键部署的能力；同时也支持全托管模式的服务，赋能服务商托管其客户资源。">
  <title>Index en - Aliyun 计算巢 x Demo</title>

  <link rel="shortcut icon" href="../../../img/favicon.ico">

  <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.0/build/pure-min.css">
  <link rel="stylesheet" href="../../../css/theme.css">
  

  

  
  

  
    <script src="../../../search/main.js"></script>
  

  

  <script src="../../../js/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>

<body>
  <div class="container">
    <div class="nav">
      <div class="nav-inner">
        <div class="logo">
          <img src="./img/logo-2x.png">
        </div>
        <div class="nav-list">
          <ul>
          
              <li><a href="#model-overview">🌟 Model Overview</a></li>
              
          
              <li><a href="#technical-specifications">🔧 Technical Specifications</a></li>
              
          
              <li><a href="#quick-start">🚀 Quick Start</a></li>
              
          
              <li><a href="#comfyui-usage-guide">🎨 ComfyUI Usage Guide</a></li>
              
                  <li><a href="#comfyui-web-interface-usage">🌐 ComfyUI Web Interface Usage</a></li>
                  
              
                  <li><a href="#api-integration">🔌 API Integration</a></li>
                  
              
                  <li><a href="#authentication-setup">🔑 Authentication Setup</a></li>
                  
              
                  <li><a href="#python-api-integration-example">💻 Python API Integration Example</a></li>
                  
              
          
          </ul>
        </div>
      </div>
    </div>
    <div class="content theme-github">
      
      <div class="content-inner">        
        
        <div style="background: linear-gradient(135deg, #2563eb, #1e40af); padding: 24px; border-radius: 8px; color: white; text-align: center; margin-bottom: 24px;">
  <h2 style="margin: 0; color: white;">🎨 Qwen-Image</h2>
  <p style="margin: 8px 0 0 0; opacity: 0.9;">Qwen Series Image Generation Foundation Model - Specialized in Complex Text Rendering & Precise Image Editing</p>
  <div style="margin-top: 20px;">
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">🎯 Text Rendering</span>
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">✨ Image Editing</span>
    <span style="background: rgba(255,255,255,0.2); color: white; padding: 4px 12px; border-radius: 12px; font-size: 14px; margin: 0 8px;">🧠 Intelligent Understanding</span>
  </div>
</div>

<h2 id="model-overview">🌟 Model Overview</h2>
<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

We are thrilled to introduce **Qwen-Image**, an image generation foundation model in the Qwen series that achieves significant breakthroughs in **complex text rendering** and **precise image editing**.

<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; margin: 16px 0; border-radius: 4px;">
  <strong>🎯 Core Advantages</strong><br>
  Experiments demonstrate that this model possesses powerful general capabilities in image generation and editing, with particularly outstanding performance in text rendering, especially for Chinese characters.
</div>

</div>

<h2 id="technical-specifications">🔧 Technical Specifications</h2>
<div style="overflow-x: auto; margin: 16px 0;">
<table style="width: 100%; border-collapse: collapse; background: white; border-radius: 6px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
  <thead style="background: #f8fafc;">
    <tr>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Specification</th>
      <th style="padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; color: #1e40af; font-weight: 600;">Details</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Model Type</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Text-to-Image Generation (T2I)</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Architecture</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Diffusion Transformer</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Supported Resolutions</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Multiple aspect ratios (1:1, 16:9, 9:16, 4:3, 3:4, 3:2, 2:3)</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Maximum Resolution</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">1664×928</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">Inference Steps</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">Recommended 50 steps</td>
    </tr>
    <tr>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9; font-weight: 500;">CFG Guidance</td>
      <td style="padding: 12px; border-bottom: 1px solid #f1f5f9;">true_cfg_scale: 4.0</td>
    </tr>
    <tr>
      <td style="padding: 12px; font-weight: 500;">License</td>
      <td style="padding: 12px;">Apache 2.0</td>
    </tr>
  </tbody>
</table>
</div>

<hr />
<h1 id="quick-start">🚀 Quick Start</h1>
<hr />
<h1 id="comfyui-usage-guide">🎨 ComfyUI Usage Guide</h1>
<h2 id="comfyui-web-interface-usage">🌐 ComfyUI Web Interface Usage</h2>
<div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 20px; margin: 16px 0;">

### 📍 Step 1: Access Interface
![img_3.png](img_3.png)
Access the ComfyUI interface through the service instance's access link

### 🔧 Step 2: Load Workflow

Select the Qwen-Image dedicated workflow template and remove the Lora node configuration
[img_4.png](img_4.png)

### ✍️ Step 3: Set Prompts

Fill in the description in the **TextEncode** node:

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">

<div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 16px; border-radius: 4px;">
<h4 style="color: #059669; margin: 0 0 8px 0;">✅ Positive Prompt</h4>
<p style="margin: 0; color: #065f46;">Describe the desired image content and style</p>
</div>

<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
<h4 style="color: #ea580c; margin: 0 0 8px 0;">❌ Negative Prompt</h4>
<p style="margin: 0; color: #9a3412;">Content you don't want to generate</p>
</div>

</div>

### ⚙️ Step 4: Configure Parameters

Set image resolution, inference steps, and other parameters

### 🎬 Step 5: Execute Generation

Click the execute button to start image generation

</div>

<hr />
<h2 id="api-integration">🔌 API Integration</h2>
<h2 id="authentication-setup">🔑 Authentication Setup</h2>
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">
<div style="background: #eff6ff; border-left: 4px solid #2563eb; padding: 16px; border-radius: 4px;">
<h4 style="color: #2563eb; margin: 0 0 8px 0;">🌐 Get Server Address</h4>
<p style="margin: 0 0 12px 0;">Record the ComfyUI server's access address</p>

![img_3.png](img_3.png)
</div>
<div style="background: #fff7ed; border-left: 4px solid #ea580c; padding: 16px; border-radius: 4px;">
<h4 style="color: #ea580c; margin: 0 0 8px 0;">🔐 Get API Token</h4>
<p style="margin: 0 0 12px 0;">Obtain the access token from the top-right corner of ComfyUI interface</p>

![img_1.png](img_1.png)
</div>

</div>

<h2 id="python-api-integration-example">💻 Python API Integration Example</h2>
<details style="border: 2px solid #2563eb; border-radius: 12px; padding: 20px; margin: 20px 0; background: linear-gradient(145deg, #f8fafc, #eff6ff); box-shadow: 0 8px 16px rgba(37, 99, 235, 0.15);">
<summary style="font-weight: bold; font-size: 18px; color: white; cursor: pointer; padding: 16px; background: linear-gradient(135deg, #2563eb, #1e40af); border-radius: 8px; margin: -20px -20px 20px -20px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); transition: all 0.3s ease; display: flex; align-items: center; box-shadow: 0 4px 8px rgba(37, 99, 235, 0.3);">
🐍 Click to expand complete Python API integration code
</summary>


<pre><code class="language-python">import requests
import json
import uuid
import time
import random
import os

# 🔧 Configuration Parameters
COMFYUI_SERVER = &quot;your-server-address&quot;
COMFYUI_TOKEN = &quot;your-api-token&quot;

# 🎯 Qwen-Image Model Files
UNET_MODEL = &quot;qwen_image_fp8_e4m3fn.safetensors&quot;
CLIP_MODEL = &quot;qwen_2.5_vl_7b_fp8_scaled.safetensors&quot;
VAE_MODEL = &quot;qwen_image_vae.safetensors&quot;

class QwenImageClient:
    def __init__(self, server=COMFYUI_SERVER, token=COMFYUI_TOKEN):
        self.base_url = f&quot;http://{server}&quot;
        self.token = token
        self.client_id = str(uuid.uuid4())
        self.headers = {
            &quot;Content-Type&quot;: &quot;application/json&quot;,
            **({&quot;Authorization&quot;: f&quot;Bearer {token}&quot;} if token else {})
        }

    def generate_image(self, prompt, negative_prompt=&quot;&quot;, width=1328, height=1328, steps=20, cfg=2.5, shift=3.1, seed=None):
        &quot;&quot;&quot;🎨 Generate Image&quot;&quot;&quot;
        if seed is None:
            seed = random.randint(1, 1000000000000000)

        workflow = {
            &quot;3&quot;: {
                &quot;inputs&quot;: {
                    &quot;seed&quot;: seed,
                    &quot;steps&quot;: steps,
                    &quot;cfg&quot;: cfg,
                    &quot;sampler_name&quot;: &quot;euler&quot;,
                    &quot;scheduler&quot;: &quot;simple&quot;,
                    &quot;denoise&quot;: 1,
                    &quot;model&quot;: [&quot;66&quot;, 0],
                    &quot;positive&quot;: [&quot;6&quot;, 0],
                    &quot;negative&quot;: [&quot;7&quot;, 0],
                    &quot;latent_image&quot;: [&quot;58&quot;, 0]
                },
                &quot;class_type&quot;: &quot;KSampler&quot;,
                &quot;_meta&quot;: {
                    &quot;title&quot;: &quot;KSampler&quot;
                }
            },
            &quot;6&quot;: {
                &quot;inputs&quot;: {
                    &quot;text&quot;: prompt,
                    &quot;clip&quot;: [&quot;38&quot;, 0]
                },
                &quot;class_type&quot;: &quot;CLIPTextEncode&quot;,
                &quot;_meta&quot;: {
                    &quot;title&quot;: &quot;CLIP Text Encode (Positive Prompt)&quot;
                }
            },
            &quot;7&quot;: {
                &quot;inputs&quot;: {
                    &quot;text&quot;: negative_prompt,
                    &quot;clip&quot;: [&quot;38&quot;, 0]
                },
                &quot;class_type&quot;: &quot;CLIPTextEncode&quot;,
                &quot;_meta&quot;: {
                    &quot;title&quot;: &quot;CLIP Text Encode (Negative Prompt)&quot;
                }
            },
            &quot;8&quot;: {
                &quot;inputs&quot;: {
                    &quot;samples&quot;: [&quot;3&quot;, 0],
                    &quot;vae&quot;: [&quot;39&quot;, 0]
                },
                &quot;class_type&quot;: &quot;VAEDecode&quot;,
                &quot;_meta&quot;: {
                    &quot;title&quot;: &quot;VAE Decode&quot;
                }
            },
            &quot;37&quot;: {
                &quot;inputs&quot;: {
                    &quot;unet_name&quot;: UNET_MODEL,
                    &quot;weight_dtype&quot;: &quot;default&quot;
                },
                &quot;class_type&quot;: &quot;UNETLoader&quot;,
                &quot;_meta&quot;: {
                    &quot;title&quot;: &quot;Load Diffusion Model&quot;
                }
            },
            &quot;38&quot;: {
                &quot;inputs&quot;: {
                    &quot;clip_name&quot;: CLIP_MODEL,
                    &quot;type&quot;: &quot;qwen_image&quot;,
                    &quot;device&quot;: &quot;default&quot;
                },
                &quot;class_type&quot;: &quot;CLIPLoader&quot;,
                &quot;_meta&quot;: {
                    &quot;title&quot;: &quot;Load CLIP&quot;
                }
            },
            &quot;39&quot;: {
                &quot;inputs&quot;: {
                    &quot;vae_name&quot;: VAE_MODEL
                },
                &quot;class_type&quot;: &quot;VAELoader&quot;,
                &quot;_meta&quot;: {
                    &quot;title&quot;: &quot;Load VAE&quot;
                }
            },
            &quot;58&quot;: {
                &quot;inputs&quot;: {
                    &quot;width&quot;: width,
                    &quot;height&quot;: height,
                    &quot;batch_size&quot;: 1
                },
                &quot;class_type&quot;: &quot;EmptySD3LatentImage&quot;,
                &quot;_meta&quot;: {
                    &quot;title&quot;: &quot;EmptySD3LatentImage&quot;
                }
            },
            &quot;60&quot;: {
                &quot;inputs&quot;: {
                    &quot;filename_prefix&quot;: &quot;qwen-image&quot;,
                    &quot;images&quot;: [&quot;8&quot;, 0]
                },
                &quot;class_type&quot;: &quot;SaveImage&quot;,
                &quot;_meta&quot;: {
                    &quot;title&quot;: &quot;Save Image&quot;
                }
            },
            &quot;66&quot;: {
                &quot;inputs&quot;: {
                    &quot;shift&quot;: shift,
                    &quot;model&quot;: [&quot;37&quot;, 0]
                },
                &quot;class_type&quot;: &quot;ModelSamplingAuraFlow&quot;,
                &quot;_meta&quot;: {
                    &quot;title&quot;: &quot;ModelSamplingAuraFlow&quot;
                }
            }
        }

        print(&quot;📤 Submitting Qwen-Image generation task...&quot;)
        response = requests.post(
            f&quot;{self.base_url}/prompt&quot;,
            headers=self.headers,
            json={&quot;prompt&quot;: workflow, &quot;client_id&quot;: self.client_id}
        )

        print(f&quot;API Response: {response.text}&quot;)
        result = response.json()
        if &quot;error&quot; in result:
            raise Exception(f&quot;Workflow error: {result['error']}&quot;)
        if &quot;prompt_id&quot; not in result:
            raise Exception(f&quot;No prompt_id in response: {result}&quot;)

        return result[&quot;prompt_id&quot;]

    def get_status(self, task_id):
        &quot;&quot;&quot;📊 Get Task Status&quot;&quot;&quot;
        try:
            # Check queue status
            queue_response = requests.get(f&quot;{self.base_url}/queue&quot;, headers=self.headers)
            queue_data = queue_response.json()

            # Check if in running queue
            if any(item[1] == task_id for item in queue_data.get(&quot;queue_running&quot;, [])):
                return &quot;processing&quot;

            # Check if in pending queue
            if any(item[1] == task_id for item in queue_data.get(&quot;queue_pending&quot;, [])):
                return &quot;pending&quot;

            # Check history
            history_response = requests.get(f&quot;{self.base_url}/history/{task_id}&quot;, headers=self.headers)
            if history_response.status_code == 200:
                history = history_response.json()
                if task_id in history:
                    return &quot;completed&quot;

            return &quot;processing&quot;
        except Exception as e:
            print(f&quot;Status check error: {e}&quot;)
            return &quot;processing&quot;

    def download_image(self, task_id, output_path=&quot;qwen_image_output.png&quot;):
        &quot;&quot;&quot;📥 Download Generated Image&quot;&quot;&quot;
        try:
            response = requests.get(f&quot;{self.base_url}/history/{task_id}&quot;, headers=self.headers)
            history = response.json()

            if task_id in history:
                outputs = history[task_id]['outputs']
                for node_id, output in outputs.items():
                    if 'images' in output:
                        for image_info in output['images']:
                            filename = image_info['filename']
                            image_response = requests.get(
                                f&quot;{self.base_url}/view?filename={filename}&quot;,
                                headers=self.headers
                            )

                            with open(output_path, &quot;wb&quot;) as f:
                                f.write(image_response.content)

                            return output_path

            return None
        except Exception as e:
            print(f&quot;Download error: {e}&quot;)
            return None

def main():
    &quot;&quot;&quot;🚀 Main Function - Execute Qwen-Image Generation Task&quot;&quot;&quot;
    client = QwenImageClient()

    try:
        print(&quot;🎨 Starting Qwen-Image generation task...&quot;)

        # 🎯 Example Prompt - Hong Kong Neon Street Scene
        prompt = '''A vibrant, warm neon-lit street scene in Hong Kong at the afternoon, with a mix of colorful Chinese and English signs glowing brightly. The atmosphere is lively, cinematic, and rain-washed with reflections on the pavement. The colors are vivid, full of pink, blue, red, and green hues. Crowded buildings with overlapping neon signs. 1980s Hong Kong style. Signs include:
&quot;龍鳳冰室&quot; &quot;金華燒臘&quot; &quot;HAPPY HAIR&quot; &quot;鴻運茶餐廳&quot; &quot;EASY BAR&quot; &quot;永發魚蛋粉&quot; &quot;添記粥麵&quot; &quot;SUNSHINE MOTEL&quot; &quot;美都餐室&quot; &quot;富記糖水&quot; &quot;太平館&quot; &quot;雅芳髮型屋&quot; &quot;STAR KTV&quot; &quot;銀河娛樂城&quot; &quot;百樂門舞廳&quot; &quot;BUBBLE CAFE&quot; &quot;萬豪麻雀館&quot; &quot;CITY LIGHTS BAR&quot; &quot;瑞祥香燭莊&quot; &quot;文記文具&quot; &quot;GOLDEN JADE HOTEL&quot; &quot;LOVELY BEAUTY&quot; &quot;合興百貨&quot; &quot;興旺電器&quot; And the background is warm yellow street and with all stores' lights on.'''

        negative_prompt = &quot;low quality, blurry, distorted, bad anatomy, deformed text&quot;

        print(f&quot;📝 Prompt: {prompt[:100]}...&quot;)

        # 🎨 Generate Image
        task_id = client.generate_image(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=1328,
            height=1328,
            steps=20,
            cfg=2.5,
            shift=3.1
        )

        print(f&quot;🆔 Task ID: {task_id}&quot;)

        # ⏳ Wait for completion
        while True:
            status = client.get_status(task_id)
            print(f&quot;📊 Current status: {status}&quot;)

            if status == &quot;completed&quot;:
                print(&quot;✅ Image generation completed!&quot;)
                break
            elif status == &quot;failed&quot;:
                print(&quot;❌ Image generation failed!&quot;)
                exit(1)

            time.sleep(10)

        # 📥 Download image
        output_file = client.download_image(task_id, &quot;qwen_image_hongkong.png&quot;)
        if output_file:
            print(f&quot;🎉 Image downloaded successfully! Saved as: {output_file}&quot;)
        else:
            print(&quot;❌ Image download failed&quot;)

    except Exception as e:
        print(f&quot;❌ Error: {e}&quot;)

# 🎯 Preset Example Functions
def generate_text_examples():
    &quot;&quot;&quot;📝 Generate Different Types of Text Rendering Examples&quot;&quot;&quot;
    client = QwenImageClient()

    examples = [
        {
            &quot;name&quot;: &quot;Coffee Shop Sign&quot;,
            &quot;prompt&quot;: '''A cozy coffee shop entrance with a wooden chalkboard sign reading &quot;Qwen Coffee ☕ 通义咖啡&quot; in beautiful handwritten style. Below it shows &quot;今日特价 Today's Special: 拿铁 Latte ¥25&quot;. The scene has warm lighting and vintage atmosphere.''',
            &quot;filename&quot;: &quot;coffee_shop_sign.png&quot;
        },
        {
            &quot;name&quot;: &quot;Math Formula Blackboard&quot;,
            &quot;prompt&quot;: '''A university classroom blackboard with mathematical equations written in white chalk: &quot;E=mc²&quot;, &quot;π≈3.14159265359&quot;, &quot;∫f(x)dx&quot;, &quot;∑(n=1 to ∞)&quot;, &quot;√(a²+b²)=c&quot;. The handwriting is clear and academic style.''',
            &quot;filename&quot;: &quot;math_blackboard.png&quot;
        },
        {
            &quot;name&quot;: &quot;Bilingual Bookstore&quot;,
            &quot;prompt&quot;: '''A traditional bookstore with bilingual signs: &quot;书香门第 Book Paradise&quot;, &quot;新书上架 New Arrivals&quot;, &quot;文学小说 Literature&quot;, &quot;历史传记 Biography&quot;, &quot;儿童读物 Children's Books&quot;. Warm wooden shelves filled with books.''',
            &quot;filename&quot;: &quot;bilingual_bookstore.png&quot;
        },
        {
            &quot;name&quot;: &quot;Japanese Ramen Shop&quot;,
            &quot;prompt&quot;: '''A Japanese ramen shop with neon signs displaying: &quot;らーめん Ramen&quot;, &quot;味噌ラーメン Miso Ramen ¥800&quot;, &quot;醤油ラーメン Shoyu Ramen ¥750&quot;, &quot;豚骨ラーメン Tonkotsu Ramen ¥850&quot;. Traditional red lanterns and warm lighting.''',
            &quot;filename&quot;: &quot;ramen_shop_signs.png&quot;
        }
    ]

    for example in examples:
        try:
            print(f&quot;\n🎨 Generating example: {example['name']}&quot;)
            task_id = client.generate_image(
                prompt=example['prompt'],
                negative_prompt=&quot;low quality, blurry, illegible text, distorted characters&quot;,
                width=1328,
                height=1328,
                steps=20,
                cfg=2.5
            )

            # Wait for completion
            while client.get_status(task_id) != &quot;completed&quot;:
                time.sleep(5)

            # Download
            output_file = client.download_image(task_id, example['filename'])
            if output_file:
                print(f&quot;✅ {example['name']} generation completed: {output_file}&quot;)

        except Exception as e:
            print(f&quot;❌ {example['name']} generation failed: {e}&quot;)

if __name__ == &quot;__main__&quot;:
    # Run main example
    main()

    # Optional: Run multiple text rendering examples
    # generate_text_examples()

</code></pre>

</details>
        
      </div>

      <div class="copyrights">© 2009-2022 Aliyun.com 版权所有</div>
    </div>
  </div>
  
  <!--
  MkDocs version      : 1.6.1
  Docs Build Date UTC : 2025-09-17 10:39:36.364573+00:00
  -->
</body>
</html>